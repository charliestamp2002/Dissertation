{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.special import comb\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_DIR = pathlib.Path(\"tracking-compressed\")\n",
    "json_gz_paths = sorted(TRACKING_DIR.glob(\"tracking_*.json.gz\"))\n",
    "\n",
    "n_files = 1 # or set to len(json_gz_paths) to load all\n",
    "\n",
    "frames = []\n",
    "players = []\n",
    "used_match_ids = []  # <- store used match_ids here\n",
    "\n",
    "for file_idx, json_gz_path in enumerate(json_gz_paths[:n_files]):\n",
    "    match_id = json_gz_path.stem  # e.g. \"tracking_g2444470\"\n",
    "    used_match_ids.append(match_id)  # <- keep track of what's loaded\n",
    "\n",
    "    records = []\n",
    "\n",
    "    with gzip.open(json_gz_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            records.append(json.loads(line))\n",
    "\n",
    "    for r in records:\n",
    "        f_data = {\n",
    "            \"match_id\": match_id,\n",
    "            \"period\": r[\"period\"],\n",
    "            \"frameIdx\": r[\"frameIdx\"],\n",
    "            \"gameClock\": r[\"gameClock\"],\n",
    "            \"lastTouch_team\": r[\"lastTouch\"],\n",
    "            \"ball_x\": r[\"ball\"][\"xyz\"][0],\n",
    "            \"ball_y\": r[\"ball\"][\"xyz\"][1],\n",
    "            \"ball_z\": r[\"ball\"][\"xyz\"][2],\n",
    "        }\n",
    "        frames.append(f_data)\n",
    "\n",
    "        for side in [\"homePlayers\", \"awayPlayers\"]:\n",
    "            for p in r[side]:\n",
    "                px, py, pz = p[\"xyz\"]\n",
    "                players.append({\n",
    "                    \"match_id\": match_id,\n",
    "                    \"period\": r[\"period\"],\n",
    "                    \"frameIdx\": r[\"frameIdx\"],\n",
    "                    \"side\": \"home\" if side == \"homePlayers\" else \"away\",\n",
    "                    \"playerId\": p[\"playerId\"],\n",
    "                    \"optaId\": str(p[\"optaId\"]),\n",
    "                    \"number\": p[\"number\"],\n",
    "                    \"x\": px, \"y\": py, \"z\": pz,\n",
    "                    \"speed\": p[\"speed\"],\n",
    "                })\n",
    "\n",
    "# Convert to DataFrames\n",
    "frames_df = pd.DataFrame(frames)\n",
    "players_df = pd.DataFrame(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract suffixes like \"g2444470\" from used tracking files\n",
    "used_match_suffixes = [match_id.split(\"_\", 1)[1].replace(\".json\", \"\") for match_id in used_match_ids]\n",
    "\n",
    "# Step 2: Gather metadata file paths from both formats\n",
    "metadata_dir = pathlib.Path(\"metadata_SecondSpectrum\")\n",
    "all_metadata_files = list(metadata_dir.glob(\"*.json\"))\n",
    "\n",
    "# Build map: match_suffix (e.g., \"g2444470\") → metadata_path\n",
    "metadata_file_map = {}\n",
    "for path in all_metadata_files:\n",
    "    filename = path.name\n",
    "    if filename.startswith(\"metadata_g\") and filename.endswith(\".json\"):\n",
    "        suffix = filename.split(\"_\")[1].split(\".\")[0]  # 'g2444470'\n",
    "    elif filename.endswith(\"_SecondSpectrum_Metadata.json\"):\n",
    "        suffix = filename.split(\"_\")[0]  # 'g2444470'\n",
    "    else:\n",
    "        continue  # skip non-matching files\n",
    "    metadata_file_map[suffix] = path\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Load metadata and build lookup for used matches\n",
    "opta_meta_lookup = {}\n",
    "\n",
    "for suffix in used_match_suffixes:\n",
    "    metadata_path = metadata_file_map.get(suffix)\n",
    "    if not metadata_path:\n",
    "        print(f\" No metadata found for match {suffix}\")\n",
    "        continue\n",
    "\n",
    "    with open(metadata_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        meta = json.load(f)\n",
    "\n",
    "    match_id = f\"tracking_{suffix}\"  # same format as tracking match_id\n",
    "\n",
    "    for side, team in [(\"homePlayers\", \"home\"), (\"awayPlayers\", \"away\")]:\n",
    "        for p in meta.get(side, []):\n",
    "            key = (match_id, str(p[\"optaId\"]))\n",
    "            opta_meta_lookup[key] = {\n",
    "                \"player_name\": p.get(\"name\"),\n",
    "                \"position\": p.get(\"position\"),\n",
    "                \"team_role\": team,\n",
    "            }\n",
    "\n",
    "print(f\" Loaded metadata for {len(opta_meta_lookup)} players.\")\n",
    "\n",
    "meta_df = pd.DataFrame([\n",
    "    {\n",
    "        \"match_id\": match_id,\n",
    "        \"optaId\": opta_id,\n",
    "        \"player_name\": info[\"player_name\"],\n",
    "        \"position\": info[\"position\"],\n",
    "        \"team_role\": info[\"team_role\"],\n",
    "    }\n",
    "    for (match_id, opta_id), info in opta_meta_lookup.items()\n",
    "])\n",
    "\n",
    "players_df[\"match_id_clean\"] = players_df[\"match_id\"].str.replace(\".json\", \"\", regex=False)\n",
    "\n",
    "# Merge using match_id and optaId as keys\n",
    "players_df = players_df.merge(\n",
    "    meta_df,\n",
    "    how=\"left\",\n",
    "    left_on=[\"match_id_clean\", \"optaId\"],\n",
    "    right_on=[\"match_id\", \"optaId\"]\n",
    ")\n",
    "\n",
    "players_df.drop(columns=[\"match_id_clean\", \"match_id_y\"], inplace=True)\n",
    "players_df.rename(columns={\"match_id_x\": \"match_id\"}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmenting Runs (across multiple matches)\n",
    "def segment_runs(players_df, speed_threshold=2.0):\n",
    "    \"\"\"\n",
    "    Segments continuous runs for each player within each match and period\n",
    "    when speed exceeds a threshold.\n",
    "    \"\"\"\n",
    "    runs = []\n",
    "    for (match_id, period, playerId), group in players_df.groupby([\"match_id\", \"period\", \"playerId\"]):\n",
    "        group = group.sort_values(\"frameIdx\")\n",
    "        current_run = []\n",
    "        for _, row in group.iterrows():\n",
    "            if row[\"speed\"] > speed_threshold:\n",
    "                current_run.append(row)\n",
    "            elif current_run:\n",
    "                runs.append(pd.DataFrame(current_run))\n",
    "                current_run = []\n",
    "        if current_run:\n",
    "            runs.append(pd.DataFrame(current_run))\n",
    "    return runs\n",
    "\n",
    "def filter_off_ball_runs_with_distance(runs_list, frames_df, players_df, min_distance=3.0):\n",
    "    \"\"\"\n",
    "    Filters runs to keep only those where:\n",
    "    - The player never touched the ball (not lastTouch)\n",
    "    - The player is always at least `min_distance` away from the ball\n",
    "    \"\"\"\n",
    "    frame_last_touch = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[\"lastTouch_team\"].to_dict()\n",
    "    ball_positions = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[[\"ball_x\", \"ball_y\"]].to_dict(\"index\")\n",
    "    \n",
    "    off_ball_runs = []\n",
    "\n",
    "    for run_df in runs_list:\n",
    "        player_id = run_df[\"playerId\"].iloc[0]\n",
    "        match_id = run_df[\"match_id\"].iloc[0]\n",
    "        period = run_df[\"period\"].iloc[0]\n",
    "        frame_idxs = run_df[\"frameIdx\"].values\n",
    "\n",
    "        is_off_ball = True\n",
    "        for frame_idx in frame_idxs:\n",
    "            key = (match_id, period, frame_idx)\n",
    "\n",
    "            # Check lastTouch\n",
    "            if frame_last_touch.get(key) == player_id:\n",
    "                is_off_ball = False\n",
    "                break\n",
    "\n",
    "            # Check distance from ball\n",
    "            ball_pos = ball_positions.get(key)\n",
    "            if ball_pos is None:\n",
    "                continue  # Skip frames with missing ball info\n",
    "\n",
    "            player_pos = run_df[run_df[\"frameIdx\"] == frame_idx][[\"x\", \"y\"]].values\n",
    "            if player_pos.size == 0:\n",
    "                continue\n",
    "\n",
    "            dist = np.linalg.norm(player_pos[0] - np.array([ball_pos[\"ball_x\"], ball_pos[\"ball_y\"]]))\n",
    "            if dist < min_distance:\n",
    "                is_off_ball = False\n",
    "                break\n",
    "\n",
    "        if is_off_ball:\n",
    "            off_ball_runs.append(run_df)\n",
    "\n",
    "    return off_ball_runs\n",
    "\n",
    "runs_list = segment_runs(players_df)\n",
    "print(f\"Total runs segmented: {len(runs_list)}\")\n",
    "\n",
    "runs_list = filter_off_ball_runs_with_distance(runs_list, frames_df, players_df, min_distance=3.0)\n",
    "print(f\"Total off-ball runs (with min distance): {len(runs_list)}\")\n",
    "\n",
    "# Annotate each run with player metadata\n",
    "annotated_runs = []\n",
    "\n",
    "for run_df in runs_list:\n",
    "    # Make a copy of the run to avoid modifying in-place\n",
    "    run_df = run_df.copy()\n",
    "\n",
    "    # Extract metadata from the first row (same for entire run)\n",
    "    meta_fields = [\"playerId\", \"optaId\", \"match_id\", \"player_name\", \"position\", \"team_role\"]\n",
    "    for field in meta_fields:\n",
    "        run_df[field] = run_df.iloc[0][field]\n",
    "\n",
    "    annotated_runs.append(run_df)\n",
    "\n",
    "# Assign a unique run_id to each run\n",
    "for i, run_df in enumerate(annotated_runs):\n",
    "    run_df[\"run_id\"] = i\n",
    "\n",
    "# Optional: Combine into one dataframe\n",
    "all_runs_df = pd.concat(annotated_runs, ignore_index=True)\n",
    "\n",
    "# Preview\n",
    "print(all_runs_df[[\"player_name\", \"position\", \"team_role\", \"x\", \"y\", \"speed\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def mirror function\n",
    "def mirror_group(group):\n",
    "\n",
    "    # y_start = group.iloc[0][\"y\"]\n",
    "\n",
    "    # if y_start < 0:\n",
    "    #     group[\"x_mirror\"] = group[\"x\"]\n",
    "    #     group[\"y_mirror\"] = -group[\"y\"]\n",
    "    # else:\n",
    "    #     group[\"x_mirror\"] = group[\"x\"]\n",
    "    #     group[\"y_mirror\"] = group[\"y\"]\n",
    "\n",
    "    y_mean = group[\"y\"].mean()\n",
    "    if y_mean < 0:\n",
    "        group[\"y_mirror\"] = -group[\"y\"]\n",
    "    else:\n",
    "        group[\"y_mirror\"] = group[\"y\"]\n",
    "    group[\"x_mirror\"] = group[\"x\"]\n",
    "\n",
    "\n",
    "    return group\n",
    "\n",
    "def should_flip_x(team_role, period):\n",
    "    \"\"\"\n",
    "    Returns True if this team in this period attacks right-to-left.\n",
    "    \"\"\"\n",
    "    if period == 1:\n",
    "        return team_role == \"away\"\n",
    "    elif period == 2:\n",
    "        return team_role == \"home\"\n",
    "    else:\n",
    "        return False  # Just in case\n",
    "\n",
    "# Apply mirroring per run\n",
    "all_runs_df = all_runs_df.groupby(\"run_id\", group_keys=False).apply(mirror_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR CENTROID CALCULATION FOR PERSON PERFORMING RUN \n",
    "\n",
    "# # Precompute centroids for all frames and both teams\n",
    "# centroid_dict = {}  # (match_id, period, frameIdx, team_side) -> centroid np.array\n",
    "\n",
    "# for (match_id, period, frame_idx), group in players_df.groupby([\"match_id\", \"period\", \"frameIdx\"]):\n",
    "#     for side in [\"home\", \"away\"]:\n",
    "#         team_players = group[(group[\"side\"] == side) & (group[\"number\"] != 1)]\n",
    "#         if not team_players.empty:\n",
    "#             centroid = team_players[[\"x\", \"y\"]].mean().values\n",
    "#         else:\n",
    "#             centroid = np.array([0.0, 0.0])\n",
    "#         centroid_dict[(match_id, period, frame_idx, side)] = centroid\n",
    "\n",
    "# # Precompute playerId → side map for each (match_id, period, frameIdx)\n",
    "# player_side_lookup = players_df.set_index([\"match_id\", \"period\", \"frameIdx\", \"playerId\"])[\"side\"].to_dict()\n",
    "\n",
    "# # Convert frames_df for fast access to lastTouch per frame\n",
    "# frame_last_touch = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[\"lastTouch\"].to_dict()\n",
    "\n",
    "# adjusted_runs_list = []\n",
    "\n",
    "# # Now adjust each run\n",
    "# for run_df in runs_list:\n",
    "#     run_df = run_df.sort_values(\"frameIdx\")\n",
    "#     match_id = run_df[\"match_id\"].iloc[0]\n",
    "#     period = run_df[\"period\"].iloc[0]\n",
    "#     start_frame = run_df[\"frameIdx\"].iloc[0]\n",
    "\n",
    "#     team_centroid = np.array([0.0, 0.0])  # fallback\n",
    "\n",
    "#     key = (match_id, period, start_frame)\n",
    "#     first_player = run_df[\"playerId\"].iloc[0]\n",
    "#     side = player_side_lookup.get((match_id, period, start_frame, first_player))\n",
    "\n",
    "#     if side is not None:\n",
    "#         team_centroid = centroid_dict.get((match_id, period, start_frame, side), team_centroid)\n",
    "\n",
    "#     run_df[\"x_c\"] = run_df[\"x\"] - team_centroid[0]\n",
    "#     run_df[\"y_c\"] = run_df[\"y\"] - team_centroid[1]\n",
    "#     run_df[\"x_mirror_c\"] = run_df[\"x_mirror\"] - team_centroid[0]\n",
    "#     run_df[\"y_mirror_c\"] = run_df[\"y_mirror\"] - team_centroid[1]\n",
    "\n",
    "#     adjusted_runs_list.append(run_df)\n",
    "\n",
    "# THIS IS FOR CENTROID CALCULATION ACCORDING TO WHOMEVER IS IN POSSESSION\n",
    "\n",
    "# # Precompute centroids for all frames and both teams\n",
    "# centroid_dict = {}  # (match_id, period, frameIdx, team_side) -> centroid np.array\n",
    "\n",
    "# for (match_id, period, frame_idx), group in players_df.groupby([\"match_id\", \"period\", \"frameIdx\"]):\n",
    "#     for side in [\"home\", \"away\"]:\n",
    "#         team_players = group[(group[\"side\"] == side) & (group[\"number\"] != 1)]\n",
    "#         if not team_players.empty:\n",
    "#             centroid = team_players[[\"x\", \"y\"]].mean().values\n",
    "#         else:\n",
    "#             centroid = np.array([0.0, 0.0])\n",
    "#         centroid_dict[(match_id, period, frame_idx, side)] = centroid\n",
    "\n",
    "# # Precompute playerId → side map for each (match_id, period, frameIdx)\n",
    "# player_side_lookup = players_df.set_index([\"match_id\", \"period\", \"frameIdx\", \"playerId\"])[\"side\"].to_dict()\n",
    "\n",
    "# # Convert frames_df for fast access to lastTouch per frame\n",
    "# frame_last_touch = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[\"lastTouch\"].to_dict()\n",
    "\n",
    "# adjusted_runs_list = []\n",
    "\n",
    "# grouped = all_runs_df.groupby([\"match_id\", \"period\", \"playerId\", \"run_id\"])  # assuming you added a unique run_id\n",
    "\n",
    "# for _, run_df in grouped:\n",
    "#     run_df = run_df.sort_values(\"frameIdx\")\n",
    "#     match_id = run_df[\"match_id\"].iloc[0]\n",
    "#     match_id = match_id.replace(\".json\", \"\")\n",
    "#     period = run_df[\"period\"].iloc[0]\n",
    "#     start_frame = run_df[\"frameIdx\"].iloc[0]\n",
    "\n",
    "#     team_centroid = np.array([0.0, 0.0])  # fallback if no possession info\n",
    "\n",
    "\n",
    "#     key = (match_id, period, start_frame)\n",
    "#     if key not in centroid_dict:\n",
    "#         print(\"Missing key:\", key)\n",
    "#     last_touch_player = frame_last_touch.get(key)\n",
    "\n",
    "#     if last_touch_player is not None:\n",
    "#         possession_side = player_side_lookup.get((match_id, period, start_frame, last_touch_player))\n",
    "#         if possession_side is not None:\n",
    "#             team_centroid = centroid_dict.get((match_id, period, start_frame, possession_side), team_centroid)\n",
    "    \n",
    "#     print(team_centroid)\n",
    "\n",
    "#     run_df[\"x_c\"] = run_df[\"x\"] - team_centroid[0]\n",
    "#     run_df[\"y_c\"] = run_df[\"y\"] - team_centroid[1]\n",
    "#     run_df[\"x_mirror_c\"] = run_df[\"x_mirror\"] - team_centroid[0]\n",
    "#     run_df[\"y_mirror_c\"] = run_df[\"y_mirror\"] - team_centroid[1]\n",
    "\n",
    "#     adjusted_runs_list.append(run_df)\n",
    "\n",
    "# # Combine into a final DataFrame\n",
    "# final_runs_df = pd.concat(adjusted_runs_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute centroids for all frames and both teams (excluding goalkeeper)\n",
    "# centroid_dict = {}\n",
    "# for (match_id, period, frame_idx), group in players_df.groupby([\"match_id\", \"period\", \"frameIdx\"]):\n",
    "#     for side in [\"home\", \"away\"]:\n",
    "#         team_players = group[(group[\"side\"] == side) & (group[\"number\"] != 1)]\n",
    "#         centroid = team_players[[\"x\", \"y\"]].mean().values if not team_players.empty else np.array([0.0, 0.0])\n",
    "#         centroid_dict[(match_id, period, frame_idx, side)] = centroid\n",
    "\n",
    "# Step 1: Precompute centroids for all frames and both teams (excluding goalkeeper)\n",
    "players_df[\"number\"] = players_df[\"number\"].astype(int)\n",
    "\n",
    "centroid_dict = {}\n",
    "for (match_id, period, frame_idx), group in players_df.groupby([\"match_id\", \"period\", \"frameIdx\"]):\n",
    "    for side in [\"home\", \"away\"]:\n",
    "        team_players = group[(group[\"side\"] == side) & (group[\"number\"] != 1)]\n",
    "        centroid = team_players[[\"x\", \"y\"]].mean().values if not team_players.empty else np.array([0.0, 0.0])\n",
    "        centroid_dict[(match_id, period, frame_idx, side)] = centroid\n",
    "\n",
    "print(f\"Centroids computed for {len(centroid_dict)} frame-side combinations.\")\n",
    "print(list(centroid_dict.items())[:5])  # show first few for inspection\n",
    "\n",
    "#print(centroid_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lastTouch and player-side lookups\n",
    "frame_last_touch_team = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[\"lastTouch_team\"].to_dict()\n",
    "player_side_lookup = players_df.set_index([\"match_id\", \"period\", \"frameIdx\", \"playerId\"])[\"side\"].to_dict()\n",
    "\n",
    "# # Pick a few random keys\n",
    "# sample_keys = list(frame_last_touch.keys())[:5]\n",
    "\n",
    "# for key in sample_keys:\n",
    "#     player_id = frame_last_touch[key]\n",
    "#     print(f\"Frame {key} → Last touch by Player ID {player_id}\")\n",
    "\n",
    "#     # Optional: Look up player info\n",
    "#     player_info = players_df[\n",
    "#         (players_df[\"match_id\"] == key[0]) &\n",
    "#         (players_df[\"period\"] == key[1]) &\n",
    "#         (players_df[\"frameIdx\"] == key[2]) &\n",
    "#         (players_df[\"playerId\"] == player_id)\n",
    "#     ]\n",
    "#     print(player_info[[\"playerId\", \"optaId\", \"player_name\", \"side\"]].drop_duplicates())\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_runs_list = []\n",
    "\n",
    "grouped = all_runs_df.groupby([\"match_id\", \"period\", \"playerId\", \"run_id\"], group_keys=False)\n",
    "\n",
    "for _, run_df in grouped:\n",
    "    run_df = run_df.sort_values(\"frameIdx\")\n",
    "    match_id = run_df[\"match_id\"].iloc[0]\n",
    "    period = run_df[\"period\"].iloc[0]\n",
    "    start_frame = run_df[\"frameIdx\"].iloc[0]\n",
    "\n",
    "    team_centroid = np.array([0.0, 0.0])  # fallback default\n",
    "\n",
    "    key = (match_id, period, start_frame)\n",
    "    possession_side = frame_last_touch_team.get(key)\n",
    "\n",
    "    team_role = run_df[\"team_role\"].iloc[0]\n",
    "\n",
    "    if possession_side is None: \n",
    "        in_possession = np.nan\n",
    "        phase_of_play = np.nan\n",
    "    else: \n",
    "        in_possession = (team_role == possession_side)\n",
    "        phase_of_play = \"attack\" if in_possession else \"defend\" \n",
    "\n",
    "    run_df[\"in_possession\"] = in_possession\n",
    "    run_df[\"phase_of_play\"] = phase_of_play\n",
    "\n",
    "    # if possession_side is not None:\n",
    "    #     team_centroid = centroid_dict.get((match_id, period, start_frame, possession_side), team_centroid)\n",
    "\n",
    "    # Always compute centroid for this player's own team. As opposed to above where we used possession side.\n",
    "    team_centroid = centroid_dict.get(\n",
    "        (match_id, period, start_frame, team_role),\n",
    "        np.array([0.0, 0.0])\n",
    "    )\n",
    "\n",
    "    #print(team_centroid)\n",
    "\n",
    "    run_df[\"x_c\"] = run_df[\"x\"] - team_centroid[0]\n",
    "    run_df[\"y_c\"] = run_df[\"y\"] - team_centroid[1]\n",
    "    run_df[\"x_mirror_c\"] = run_df[\"x_mirror\"] - team_centroid[0]\n",
    "    run_df[\"y_mirror_c\"] = run_df[\"y_mirror\"] - team_centroid[1]\n",
    "\n",
    "    flip_x = should_flip_x(team_role, period)\n",
    "    if flip_x:\n",
    "        run_df[\"x_mirror\"] = -run_df[\"x_mirror\"]\n",
    "        run_df[\"x_mirror_c\"] = -run_df[\"x_mirror_c\"]\n",
    "\n",
    "    adjusted_runs_list.append(run_df)\n",
    "\n",
    "final_runs_df = pd.concat(adjusted_runs_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(final_runs_df[\"x_mirror_c\"], bins=500, alpha=0.4, label=\"x_mirror_c\")\n",
    "plt.hist(final_runs_df[\"x\"], bins=500, alpha=0.4, label=\"x\")\n",
    "plt.hist(final_runs_df[\"x_c\"], bins=500, alpha=0.4, label=\"x_c\")\n",
    "plt.hist(final_runs_df[\"x_mirror\"], bins=500, alpha=0.4, label=\"x_mirror\")\n",
    "plt.title(\"Distribution of x_mirror_c, x, x_c, and x_mirror\")\n",
    "plt.xlabel(\"Position (x-axis)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(final_runs_df[\"y_mirror_c\"], bins=500, alpha=0.4, label=\"y_mirror_c\")\n",
    "plt.hist(final_runs_df[\"y\"], bins=500, alpha=1.0, label=\"y\")\n",
    "plt.hist(final_runs_df[\"y_c\"], bins=500, alpha=0.4, label=\"y_c\")\n",
    "plt.hist(final_runs_df[\"y_mirror\"], bins=500, alpha=0.4, label=\"y_mirror\")\n",
    "plt.title(\"Distribution of y_mirror_c, y, y_c, and y_mirror\")\n",
    "plt.xlabel(\"Position (y-axis)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid\n",
    "x_edges = np.linspace(-52.5, 52.5, 4)   # splits pitch length into thirds\n",
    "y_edges = np.linspace(-34, 34, 4)       # splits width into thirds\n",
    "\n",
    "def get_zone(x, y, x_edges, y_edges):\n",
    "    x_bin = np.digitize([x], x_edges)[0] - 1\n",
    "    y_bin = np.digitize([y], y_edges)[0] - 1\n",
    "    x_bin = min(max(x_bin, 0), len(x_edges)-2)\n",
    "    y_bin = min(max(y_bin, 0), len(y_edges)-2)\n",
    "    zone_idx = y_bin * (len(x_edges)-1) + x_bin + 1\n",
    "    return zone_idx\n",
    "\n",
    "# zone_records = []\n",
    "\n",
    "# for run_id, run_df in final_runs_df.groupby(\"run_id\"):\n",
    "#     start_x = run_df[\"x_mirror_c\"].iloc[0]\n",
    "#     start_y = run_df[\"y_mirror_c\"].iloc[0]\n",
    "\n",
    "#     end_x = run_df[\"x_mirror_c\"].iloc[-1]\n",
    "#     end_y = run_df[\"y_mirror_c\"].iloc[-1]\n",
    "\n",
    "#     start_zone = get_zone(start_x, start_y, x_edges, y_edges)\n",
    "#     end_zone = get_zone(end_x, end_y, x_edges, y_edges)\n",
    "\n",
    "#     phase_of_play = run_df[\"phase_of_play\"].iloc[0]\n",
    "#     in_possession = run_df[\"in_possession\"].iloc[0]\n",
    "#     team_role = run_df[\"team_role\"].iloc[0]\n",
    "#     position = run_df[\"position\"].iloc[0]\n",
    "\n",
    "#     zone_records.append({\n",
    "#         \"run_id\": run_id,\n",
    "#         \"start_zone\": start_zone,\n",
    "#         \"end_zone\": end_zone,\n",
    "#         \"phase_of_play\": phase_of_play,\n",
    "#         \"in_possession\": in_possession,\n",
    "#         \"team_role\": team_role,\n",
    "#         \"position\": position\n",
    "#     })\n",
    "\n",
    "# zones_df = pd.DataFrame(zone_records)\n",
    "# print(zones_df.head())\n",
    "\n",
    "zone_records = []\n",
    "\n",
    "for run_id, run_df in final_runs_df.groupby(\"run_id\"):\n",
    "    # Mirrored & centered positions\n",
    "    start_x_mirror_c = run_df[\"x_mirror_c\"].iloc[0]\n",
    "    start_y_mirror_c = run_df[\"y_mirror_c\"].iloc[0]\n",
    "\n",
    "    end_x_mirror_c = run_df[\"x_mirror_c\"].iloc[-1]\n",
    "    end_y_mirror_c = run_df[\"y_mirror_c\"].iloc[-1]\n",
    "\n",
    "    start_zone = get_zone(start_x_mirror_c, start_y_mirror_c, x_edges, y_edges)\n",
    "    end_zone = get_zone(end_x_mirror_c, end_y_mirror_c, x_edges, y_edges)\n",
    "\n",
    "    # Absolute pitch positions\n",
    "    start_x_abs = run_df[\"x\"].iloc[0]\n",
    "    start_y_abs = run_df[\"y\"].iloc[0]\n",
    "\n",
    "    end_x_abs = run_df[\"x\"].iloc[-1]\n",
    "    end_y_abs = run_df[\"y\"].iloc[-1]\n",
    "\n",
    "    start_zone_abs = get_zone(start_x_abs, start_y_abs, x_edges, y_edges)\n",
    "    end_zone_abs = get_zone(end_x_abs, end_y_abs, x_edges, y_edges)\n",
    "\n",
    "    phase_of_play = run_df[\"phase_of_play\"].iloc[0]\n",
    "    in_possession = run_df[\"in_possession\"].iloc[0]\n",
    "    team_role = run_df[\"team_role\"].iloc[0]\n",
    "    position = run_df[\"position\"].iloc[0]\n",
    "\n",
    "    zone_records.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"start_zone\": start_zone,\n",
    "        \"end_zone\": end_zone,\n",
    "        \"start_zone_absolute\": start_zone_abs,\n",
    "        \"end_zone_absolute\": end_zone_abs,\n",
    "        \"phase_of_play\": phase_of_play,\n",
    "        \"in_possession\": in_possession,\n",
    "        \"team_role\": team_role,\n",
    "        \"position\": position\n",
    "    })\n",
    "\n",
    "zones_df = pd.DataFrame(zone_records)\n",
    "print(zones_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Adjust mirrored coordinates relative to possession-side team centroid\n",
    "# adjusted_runs_list = []\n",
    "\n",
    "# for run_id, run_df in all_runs_df.groupby(\"run_id\"):\n",
    "#     run_df = run_df.copy()\n",
    "#     run_df = run_df.sort_values(\"frameIdx\")\n",
    "\n",
    "#     match_id = run_df[\"match_id\"].iloc[0]\n",
    "#     period = run_df[\"period\"].iloc[0]\n",
    "#     start_frame = run_df[\"frameIdx\"].iloc[0]\n",
    "\n",
    "#     team_centroid = np.array([0.0, 0.0])  # fallback\n",
    "#     key = (match_id, period, start_frame)\n",
    "#     last_touch_player = frame_last_touch.get(key)\n",
    "\n",
    "#     if last_touch_player is not None:\n",
    "#         side_key = (match_id, period, start_frame, last_touch_player)\n",
    "#         possession_side = player_side_lookup.get(side_key)\n",
    "#         if possession_side is not None:\n",
    "#             team_centroid = centroid_dict.get((match_id, period, start_frame, possession_side), team_centroid)\n",
    "\n",
    "#     run_df[\"x_c\"] = run_df[\"x\"] - team_centroid[0]\n",
    "#     run_df[\"y_c\"] = run_df[\"y\"] - team_centroid[1]\n",
    "#     run_df[\"x_mirror_c\"] = run_df[\"x_mirror\"] - team_centroid[0]\n",
    "#     run_df[\"y_mirror_c\"] = run_df[\"y_mirror\"] - team_centroid[1]\n",
    "\n",
    "#     adjusted_runs_list.append(run_df)\n",
    "\n",
    "# # Step 4: Combine into final DataFrame\n",
    "# final_runs_df = pd.concat(adjusted_runs_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equation (5): Bézier basis function\n",
    "def bernstein_poly(p, P, t):\n",
    "    return comb(P - 1, p) * (t**p) * ((1 - t)**(P - 1 - p))\n",
    "\n",
    "# Equation (7): Design matrix for Bézier fitting\n",
    "def bezier_design_matrix(num_points, num_control_points):\n",
    "    t_vals = np.linspace(0, 1, num_points)\n",
    "    X = np.stack([bernstein_poly(p, num_control_points, t_vals) for p in range(num_control_points)], axis=1)\n",
    "    return X  # shape: [num_points, num_control_points]\n",
    "\n",
    "# Equation (6): Fit Bézier curve via least squares\n",
    "def fit_bezier_curve(coords, num_control_points):\n",
    "    \"\"\"\n",
    "    coords: shape [N, 2] — sequence of (x, y) points\n",
    "    returns: control_points [P, 2]\n",
    "    \"\"\"\n",
    "    N = coords.shape[0]\n",
    "    X = bezier_design_matrix(N, num_control_points)  # shape [N, P]\n",
    "    \n",
    "    # Solve least squares for x and y separately\n",
    "    theta_x, _, _, _ = np.linalg.lstsq(X, coords[:, 0], rcond=None)\n",
    "    theta_y, _, _, _ = np.linalg.lstsq(X, coords[:, 1], rcond=None)\n",
    "    \n",
    "    control_points = np.stack([theta_x, theta_y], axis=1)  # shape: [P, 2]\n",
    "    return control_points\n",
    "\n",
    "# Equation (4): Evaluate Bézier curve at t using control points θ\n",
    "def evaluate_bezier_curve(control_points, num_points=50):\n",
    "    \"\"\"\n",
    "    Returns sampled points along the Bézier curve.\n",
    "    \"\"\"\n",
    "    P = control_points.shape[0]\n",
    "    X = bezier_design_matrix(num_points, P)  # shape [num_points, P]\n",
    "    curve = X @ control_points  # shape: [num_points, 2]\n",
    "    return curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_coords(coords, num_points=50):\n",
    "    from scipy.interpolate import interp1d\n",
    "    if len(coords) < 2:\n",
    "        return np.tile(coords[0], (num_points, 1))  # Edge case\n",
    "    distances = np.cumsum(np.linalg.norm(np.diff(coords, axis=0), axis=1))\n",
    "    distances = np.insert(distances, 0, 0.0)\n",
    "    total_length = distances[-1]\n",
    "    if total_length == 0:\n",
    "        return np.tile(coords[0], (num_points, 1))\n",
    "    normalized_dist = distances / total_length\n",
    "    interp_func = interp1d(normalized_dist, coords, axis=0, kind='linear')\n",
    "    uniform_dist = np.linspace(0, 1, num_points)\n",
    "    return interp_func(uniform_dist)\n",
    "\n",
    "def compute_l1_distance(traj, bezier_curve):\n",
    "    \"\"\"\n",
    "    traj, bezier_curve: both of shape [num_points, 2]\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(traj - bezier_curve))  # L1 averaged over all points and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 10\n",
    "tolerance = 1e-3  # Minimum improvement in objective to continue\n",
    "num_points = 50\n",
    "num_control_points = 4\n",
    "k_clusters = 70\n",
    "\n",
    "# Initialize cluster centers (Bézier curves)\n",
    "random.seed(42)\n",
    "initial_centroids = random.sample(adjusted_runs_list, k_clusters)\n",
    "cluster_control_points = []\n",
    "\n",
    "for run in initial_centroids:\n",
    "    coords = run[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "    control_pts = fit_bezier_curve(coords, num_control_points)\n",
    "    cluster_control_points.append(control_pts)\n",
    "\n",
    "cluster_control_points = np.array(cluster_control_points)\n",
    "previous_objective = float('inf')\n",
    "\n",
    "for it in range(max_iterations):\n",
    "    # Assignment step\n",
    "    assignments = []\n",
    "    objective_distances = []\n",
    "\n",
    "    for run_id, run_df in final_runs_df.groupby(\"run_id\"):\n",
    "        coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "        # resampled_coords = resample_coords(coords, num_points=num_points)\n",
    "\n",
    "        # min_dist = float(\"inf\")\n",
    "        # assigned_cluster = -1\n",
    "\n",
    "        # for cluster_idx, control_pts in enumerate(cluster_control_points):\n",
    "        #     bezier_curve = evaluate_bezier_curve(control_pts, num_points=num_points)\n",
    "        #     dist = compute_l1_distance(resampled_coords, bezier_curve)\n",
    "        #     if dist < min_dist:\n",
    "        #         min_dist = dist\n",
    "        #         assigned_cluster = cluster_idx\n",
    "\n",
    "        # assignments.append(assigned_cluster)\n",
    "        # objective_distances.append(min_dist)\n",
    "\n",
    "        resampled_coords = resample_coords(coords, num_points=num_points)\n",
    "        if resampled_coords is None:\n",
    "            continue  # skip bad run\n",
    "\n",
    "        min_dist = float(\"inf\")\n",
    "        assigned_cluster = -1\n",
    "\n",
    "        for cluster_idx, control_pts in enumerate(cluster_control_points):\n",
    "            bezier_curve = evaluate_bezier_curve(control_pts, num_points=num_points)\n",
    "            dist = compute_l1_distance(resampled_coords, bezier_curve)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                assigned_cluster = cluster_idx\n",
    "\n",
    "        # assignments.append(assigned_cluster)\n",
    "\n",
    "            # Save metadata + cluster assignment\n",
    "        assignments.append({\n",
    "            \"run_id\": run_id,\n",
    "            \"assigned_cluster\": assigned_cluster,\n",
    "            \"min_distance\": min_dist,\n",
    "            \"playerId\": run_df[\"playerId\"].iloc[0],\n",
    "            \"player_name\": run_df[\"player_name\"].iloc[0],\n",
    "            \"position\": run_df[\"position\"].iloc[0],\n",
    "            \"team_role\": run_df[\"team_role\"].iloc[0],\n",
    "            \"match_id\": run_df[\"match_id\"].iloc[0],\n",
    "        })\n",
    "\n",
    "        assignments_df = pd.DataFrame(assignments)\n",
    "\n",
    "        #print(assignments_df.head())\n",
    "\n",
    "        objective_distances.append(min_dist)\n",
    "\n",
    "    objective = np.mean(objective_distances)\n",
    "    print(f\"Iteration {it}: Mean objective = {objective:.4f}\")\n",
    "\n",
    "    # Check for convergence\n",
    "    improvement = previous_objective - objective\n",
    "    if improvement < tolerance:\n",
    "        print(f\"Converged (Δ={improvement:.6f}) at iteration {it}\")\n",
    "        break\n",
    "    previous_objective = objective\n",
    "\n",
    "    # Update step\n",
    "    new_cluster_control_points = []\n",
    "\n",
    "    for cluster_idx in range(k_clusters):\n",
    "        #assigned_indices = [i for i, a in enumerate(assignments) if a == cluster_idx]\n",
    "        assigned_indices = [i for i, a in enumerate(assignments) if a[\"assigned_cluster\"] == cluster_idx]\n",
    "        if not assigned_indices:\n",
    "            new_cluster_control_points.append(cluster_control_points[cluster_idx])\n",
    "            continue\n",
    "\n",
    "        cluster_coords = []\n",
    "        for idx in assigned_indices:\n",
    "            run_id = assignments_df.loc[idx, \"run_id\"]\n",
    "            #run_df = all_runs_df[all_runs_df[\"run_id\"] == run_id]\n",
    "            run_df = final_runs_df[final_runs_df[\"run_id\"] == run_id]\n",
    "\n",
    "            coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "            resampled = resample_coords(coords, num_points=num_points)\n",
    "            # cluster_coords.append(resampled)\n",
    "            if resampled is not None:\n",
    "                cluster_coords.append(resampled)\n",
    "\n",
    "        cluster_coords = np.stack(cluster_coords, axis=0)\n",
    "        mean_coords = np.mean(cluster_coords, axis=0)\n",
    "        new_control_pts = fit_bezier_curve(mean_coords, num_control_points)\n",
    "        new_cluster_control_points.append(new_control_pts)\n",
    "\n",
    "    cluster_control_points = np.array(new_cluster_control_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build assignments DataFrame\n",
    "assignments_df = pd.DataFrame(assignments)\n",
    "\n",
    "assignments_zones = assignments_df.merge(\n",
    "    zones_df,\n",
    "    on=\"run_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "#print(assignments_zones.head())\n",
    "\n",
    "print(assignments_zones.columns)\n",
    "\n",
    "# Drop duplicates\n",
    "assignments_zones.drop(columns=[\n",
    "    \"position_y\",\n",
    "    \"team_role_y\"\n",
    "], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Rename x columns back to plain names\n",
    "assignments_zones.rename(columns={\n",
    "    \"position_x\": \"position\",\n",
    "    \"team_role_x\": \"team_role\",\n",
    "}, inplace=True)\n",
    "\n",
    "# print(assignments_zones.head())\n",
    "# print(assignments_zones.columns)\n",
    "\n",
    "\n",
    "# Count number of runs per position per cluster\n",
    "position_detail_counts = (\n",
    "    assignments_zones\n",
    "    .groupby([\"assigned_cluster\", \"position\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"num_runs\")\n",
    "    .sort_values([\"assigned_cluster\", \"num_runs\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "print(position_detail_counts.head(20))\n",
    "\n",
    "\n",
    "position_pivot = (\n",
    "    position_detail_counts\n",
    "    .pivot_table(index=\"assigned_cluster\",\n",
    "                 columns=\"position\",\n",
    "                 values=\"num_runs\",\n",
    "                 fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(position_pivot.head())\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# sns.barplot(\n",
    "#     data=position_detail_counts,\n",
    "#     x=\"assigned_cluster\",\n",
    "#     y=\"num_runs\",\n",
    "#     hue=\"position\"\n",
    "# )\n",
    "# plt.title(\"Run Counts per Cluster by Specific Position\")\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering for specific positions: \n",
    "\n",
    "filter only LB runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_runs = assignments_zones[assignments_zones[\"position\"] == \"LB\"]\n",
    "\n",
    "print(lb_runs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want only clusters containing LB runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_clusters = lb_runs[\"assigned_cluster\"].unique()\n",
    "print(\"Clusters with LB runs:\", lb_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep first row of each run\n",
    "runs_meta_df = final_runs_df.groupby(\"run_id\", as_index=False).first()\n",
    "\n",
    "# Merge metadata into assignments\n",
    "merged_df = assignments_df.merge(\n",
    "    runs_meta_df,\n",
    "    on=\"run_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Clean up columns\n",
    "merged_df.drop(columns=[\n",
    "    \"position_y\",\n",
    "    \"player_name_y\",\n",
    "    \"team_role_y\",\n",
    "    \"match_id_y\",\n",
    "    \"playerId_y\",\n",
    "], inplace=True, errors=\"ignore\")\n",
    "\n",
    "merged_df.rename(columns={\n",
    "    \"player_name_x\": \"player_name\",\n",
    "    \"position_x\": \"position\",\n",
    "    \"team_role_x\": \"team_role\",\n",
    "    \"match_id_x\": \"match_id\",\n",
    "    \"playerId_x\": \"playerId\",\n",
    "}, inplace=True)\n",
    "\n",
    "#print(\"merged_df columns:\", merged_df.columns)\n",
    "\n",
    "# Group and count\n",
    "position_counts = (\n",
    "    merged_df\n",
    "    .groupby([\"assigned_cluster\", \"position\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"num_runs\")\n",
    "    .sort_values([\"assigned_cluster\", \"num_runs\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "#print(position_counts.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_positions = merged_df[\"position\"].dropna().unique()\n",
    "print(\"Unique positions found:\", unique_positions)\n",
    "print(\"Total unique positions:\", len(unique_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of fine-grained positions → high-level buckets\n",
    "position_bucket_map = {\n",
    "    \"GK\": \"sub\",       # treat as non-field player for running\n",
    "    \"SUB\": \"sub\",\n",
    "    \n",
    "    # Defenders\n",
    "    \"CB\": \"defender\",\n",
    "    \"RCB\": \"defender\",\n",
    "    \"LCB\": \"defender\",\n",
    "    \"RB\": \"defender\",\n",
    "    \"LB\": \"defender\",\n",
    "    \"RWB\": \"defender\",\n",
    "    \"LWB\": \"defender\",\n",
    "    \n",
    "    # Midfielders\n",
    "    \"CDM\": \"midfielder\",\n",
    "    \"RDM\": \"midfielder\",\n",
    "    \"LDM\": \"midfielder\",\n",
    "    \"CM\": \"midfielder\",\n",
    "    \"RCM\": \"midfielder\",\n",
    "    \"LCM\": \"midfielder\",\n",
    "    \"CAM\": \"midfielder\",\n",
    "    \"RM\": \"midfielder\",\n",
    "    \"LM\": \"midfielder\",\n",
    "    \n",
    "    # Attackers\n",
    "    \"LW\": \"attacker\",\n",
    "    \"RW\": \"attacker\",\n",
    "    \"ST\": \"attacker\",\n",
    "    \"CF\": \"attacker\",\n",
    "    \"RF\": \"attacker\",\n",
    "    \"LF\": \"attacker\",\n",
    "}\n",
    "\n",
    "# Map positions to buckets\n",
    "merged_df[\"position_bucket\"] = merged_df[\"position\"].map(\n",
    "    lambda pos: position_bucket_map.get(pos, \"unknown\")\n",
    ")\n",
    "\n",
    "print(merged_df[[\"assigned_cluster\", \"position\", \"position_bucket\"]].head(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_counts = (\n",
    "    merged_df\n",
    "    .groupby([\"assigned_cluster\", \"position_bucket\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"num_runs\")\n",
    "    .sort_values([\"assigned_cluster\", \"num_runs\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "print(bucket_counts.head(20))\n",
    "\n",
    "bucket_pivot = (\n",
    "    bucket_counts\n",
    "    .pivot_table(index=\"assigned_cluster\", \n",
    "                 columns=\"position_bucket\", \n",
    "                 values=\"num_runs\", \n",
    "                 fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(bucket_pivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_clusters_grid(cluster_control_points, final_runs_df, assignments, samples_per_cluster=50, rows=10, cols=7):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Convert assignments to a DataFrame for easy filtering\n",
    "    assignments_df = pd.DataFrame(assignments)\n",
    "\n",
    "    for cluster_idx in range(len(cluster_control_points)):\n",
    "        ax = axes[cluster_idx]\n",
    "\n",
    "        # Plot Bézier center curve\n",
    "        bezier_curve = evaluate_bezier_curve(cluster_control_points[cluster_idx], num_points=50)\n",
    "        ax.plot(bezier_curve[:, 0], bezier_curve[:, 1], 'k-', linewidth=2, label=\"Cluster\")\n",
    "\n",
    "        # Find runs assigned to this cluster\n",
    "        run_ids_in_cluster = assignments_df.loc[\n",
    "            assignments_df[\"assigned_cluster\"] == cluster_idx, \"run_id\"\n",
    "        ].tolist()\n",
    "\n",
    "        # Randomly sample some of them\n",
    "        if run_ids_in_cluster:\n",
    "            sampled_run_ids = random.sample(\n",
    "                run_ids_in_cluster,\n",
    "                min(samples_per_cluster, len(run_ids_in_cluster))\n",
    "            )\n",
    "\n",
    "            for run_id in sampled_run_ids:\n",
    "                run_df = final_runs_df[final_runs_df[\"run_id\"] == run_id]\n",
    "                coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "                ax.plot(coords[:, 0], coords[:, 1], alpha=0.5)\n",
    "\n",
    "        ax.set_title(f\"Cluster {cluster_idx}\\n(n={len(run_ids_in_cluster)})\", fontsize=9)\n",
    "        ax.axis(\"equal\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for i in range(len(cluster_control_points), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_all_clusters_grid(cluster_control_points, final_runs_df, assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pitch(ax, pitch_length=105, pitch_width=68):\n",
    "    \"\"\"\n",
    "    Draws a football pitch centered around (0, 0) on the given matplotlib axis.\n",
    "    \"\"\"\n",
    "    half_length = pitch_length / 2\n",
    "    half_width = pitch_width / 2\n",
    "\n",
    "    # Outer boundary & centre line\n",
    "    ax.plot([-half_length, -half_length, half_length, half_length, -half_length],\n",
    "            [-half_width, half_width, half_width, -half_width, -half_width], color=\"black\")\n",
    "    ax.plot([0, 0], [-half_width, half_width], color=\"black\")\n",
    "\n",
    "    # Left penalty area\n",
    "    ax.plot([-half_length + 16.5, -half_length + 16.5], [-13.84, 13.84], color=\"black\")\n",
    "    ax.plot([-half_length, -half_length + 16.5], [-13.84, -13.84], color=\"black\")\n",
    "    ax.plot([-half_length, -half_length + 16.5], [13.84, 13.84], color=\"black\")\n",
    "\n",
    "    # Right penalty area\n",
    "    ax.plot([half_length - 16.5, half_length - 16.5], [-13.84, 13.84], color=\"black\")\n",
    "    ax.plot([half_length, half_length - 16.5], [-13.84, -13.84], color=\"black\")\n",
    "    ax.plot([half_length, half_length - 16.5], [13.84, 13.84], color=\"black\")\n",
    "\n",
    "    # Center circle\n",
    "    circle = plt.Circle((0, 0), 9.15, color=\"black\", fill=False)\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "    ax.set_xlim(-half_length, half_length)\n",
    "    ax.set_ylim(-half_width, half_width)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# def plot_all_cluster_trajectories_on_pitch(\n",
    "#     final_runs_df,\n",
    "#     assignments,\n",
    "#     cluster_control_points,\n",
    "#     num_control_points=4,\n",
    "#     max_runs_per_cluster=30\n",
    "# ):\n",
    "#     num_clusters = len(cluster_control_points)\n",
    "#     fig, axes = plt.subplots(7, 10, figsize=(30, 20))  # adjust grid for k clusters\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     assignments_df = pd.DataFrame(assignments)\n",
    "\n",
    "#     for cluster_idx in range(num_clusters):\n",
    "#         ax = axes[cluster_idx]\n",
    "#         draw_pitch(ax)\n",
    "\n",
    "#         # Find all run_ids assigned to this cluster\n",
    "#         cluster_run_ids = assignments_df.loc[\n",
    "#             assignments_df[\"assigned_cluster\"] == cluster_idx, \"run_id\"\n",
    "#         ].tolist()\n",
    "\n",
    "#         if len(cluster_run_ids) > max_runs_per_cluster:\n",
    "#             cluster_run_ids = random.sample(cluster_run_ids, max_runs_per_cluster)\n",
    "\n",
    "#         for run_id in cluster_run_ids:\n",
    "#             run_df = final_runs_df[final_runs_df[\"run_id\"] == run_id]\n",
    "            \n",
    "#             coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "#             if coords.shape[0] < 2:\n",
    "#                 continue\n",
    "\n",
    "#             resampled = resample_coords(coords, num_points=50)\n",
    "#             control_pts = fit_bezier_curve(resampled, num_control_points)\n",
    "\n",
    "#             # Recover start location to shift back to pitch space\n",
    "#             start_pos = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values[0]\n",
    "#             shifted_ctrl_pts = control_pts - control_pts[0] + start_pos\n",
    "#             bezier_curve = evaluate_bezier_curve(shifted_ctrl_pts, num_points=50)\n",
    "\n",
    "#             ax.plot(bezier_curve[:, 0], bezier_curve[:, 1], alpha=0.2, color=\"blue\")\n",
    "\n",
    "#         ax.set_title(f\"Cluster {cluster_idx}\", fontsize=8)\n",
    "\n",
    "#     # Hide unused plots\n",
    "#     for i in range(num_clusters, len(axes)):\n",
    "#         axes[i].axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.suptitle(\"All Bézier Run Trajectories per Cluster (On-Pitch View)\", fontsize=16, y=1.02)\n",
    "#     plt.show()\n",
    "\n",
    "# plot_all_cluster_trajectories_on_pitch(\n",
    "#     final_runs_df,\n",
    "#     assignments,\n",
    "#     cluster_control_points,\n",
    "#     num_control_points=4,\n",
    "#     max_runs_per_cluster=100\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_all_cluster_trajectories_on_pitch(\n",
    "#     final_runs_df,\n",
    "#     assignments,\n",
    "#     cluster_control_points,\n",
    "#     bucket_pivot,\n",
    "#     num_control_points=4,\n",
    "#     max_runs_per_cluster=30,\n",
    "#     plot_absolute_positions = True\n",
    "# ):\n",
    "#     num_clusters = len(cluster_control_points)\n",
    "#     fig, axes = plt.subplots(7, 10, figsize=(30, 20))  # adjust grid for k clusters\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     assignments_df = pd.DataFrame(assignments)\n",
    "\n",
    "#     # Set index for quick lookups\n",
    "#     bucket_pivot = bucket_pivot.set_index(\"assigned_cluster\")\n",
    "\n",
    "#     for cluster_idx in range(num_clusters):\n",
    "#         ax = axes[cluster_idx]\n",
    "#         draw_pitch(ax)\n",
    "\n",
    "#         # Plot runs\n",
    "#         cluster_run_ids = assignments_df.loc[\n",
    "#             assignments_df[\"assigned_cluster\"] == cluster_idx, \"run_id\"\n",
    "#         ].tolist()\n",
    "\n",
    "#         if len(cluster_run_ids) > max_runs_per_cluster:\n",
    "#             cluster_run_ids = random.sample(cluster_run_ids, max_runs_per_cluster)\n",
    "\n",
    "#         for run_id in cluster_run_ids:\n",
    "#             run_df = final_runs_df[final_runs_df[\"run_id\"] == run_id]\n",
    "\n",
    "#             coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "#             if coords.shape[0] < 2:\n",
    "#                 continue\n",
    "\n",
    "#             resampled = resample_coords(coords, num_points=50)\n",
    "#             control_pts = fit_bezier_curve(resampled, num_control_points)\n",
    "\n",
    "#             if plot_absolute_positions:\n",
    "#                 # Recover original start location\n",
    "#                 start_pos = run_df[[\"x\", \"y\"]].values[0]\n",
    "#                 shifted_ctrl_pts = control_pts - control_pts[0] + start_pos\n",
    "#                 bezier_curve = evaluate_bezier_curve(\n",
    "#                     shifted_ctrl_pts, num_points=50\n",
    "#                 )\n",
    "#             else:\n",
    "#                 # Keep in mirrored + centroid-relative space\n",
    "#                 bezier_curve = evaluate_bezier_curve(\n",
    "#                     control_pts, num_points=50\n",
    "#                 )\n",
    "\n",
    "#             ax.plot(bezier_curve[:, 0], bezier_curve[:, 1], alpha=0.2, color=\"blue\")\n",
    "\n",
    "#             # # Recover start location to shift back to pitch space\n",
    "#             # start_pos = run_df[[\"x\", \"y\"]].values[0]\n",
    "#             # shifted_ctrl_pts = control_pts - control_pts[0] + start_pos\n",
    "#             # bezier_curve = evaluate_bezier_curve(shifted_ctrl_pts, num_points=50)\n",
    "\n",
    "#             # ax.plot(bezier_curve[:, 0], bezier_curve[:, 1], alpha=0.2, color=\"blue\")\n",
    "\n",
    "#         # Add text box with position bucket counts\n",
    "#         if cluster_idx in bucket_pivot.index:\n",
    "#             row = bucket_pivot.loc[cluster_idx]\n",
    "#             text_lines = []\n",
    "#             for bucket in [\"attacker\", \"midfielder\", \"defender\", \"sub\", \"unknown\"]:\n",
    "#                 if bucket in row and row[bucket] > 0:\n",
    "#                     text_lines.append(f\"{bucket}: {int(row[bucket])}\")\n",
    "#             text = \"\\n\".join(text_lines)\n",
    "#             ax.text(\n",
    "#                 0.5, 1.05, text,\n",
    "#                 transform=ax.transAxes,\n",
    "#                 ha=\"center\", va=\"bottom\",\n",
    "#                 fontsize=8,\n",
    "#                 bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
    "#             )\n",
    "\n",
    "#         ax.set_title(f\"Cluster {cluster_idx}\", fontsize=8)\n",
    "\n",
    "#     for i in range(num_clusters, len(axes)):\n",
    "#         axes[i].axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.suptitle(\"All Bézier Run Trajectories per Cluster (On-Pitch View)\", fontsize=16, y=1.02)\n",
    "#     plt.show()\n",
    "\n",
    "# plot_all_cluster_trajectories_on_pitch(\n",
    "#     final_runs_df,\n",
    "#     assignments,\n",
    "#     cluster_control_points,\n",
    "#     bucket_pivot=bucket_pivot,\n",
    "#     num_control_points=4,\n",
    "#     max_runs_per_cluster=100,\n",
    "#     plot_absolute_positions=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_all_cluster_trajectories_on_pitch(\n",
    "#     final_runs_df,\n",
    "#     assignments_zones,\n",
    "#     cluster_control_points,\n",
    "#     bucket_pivot,\n",
    "#     num_control_points=4,\n",
    "#     max_runs_per_cluster=30,\n",
    "#     plot_absolute_positions=True,\n",
    "#     start_zones=None,\n",
    "#     end_zones=None,\n",
    "#     phases_of_play=None,\n",
    "#     positions=None\n",
    "# ):\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import random\n",
    "\n",
    "#     num_clusters = len(cluster_control_points)\n",
    "#     fig, axes = plt.subplots(7, 10, figsize=(30, 20))  # adjust grid as needed\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     # --- FILTERING ---\n",
    "#     filtered_assignments = assignments_zones.copy()\n",
    "\n",
    "#     if start_zones is not None:\n",
    "#         filtered_assignments = filtered_assignments[\n",
    "#             filtered_assignments[\"start_zone\"].isin(start_zones)\n",
    "#         ]\n",
    "\n",
    "#     if end_zones is not None:\n",
    "#         filtered_assignments = filtered_assignments[\n",
    "#             filtered_assignments[\"end_zone\"].isin(end_zones)\n",
    "#         ]\n",
    "\n",
    "#     if phases_of_play is not None:\n",
    "#         filtered_assignments = filtered_assignments[\n",
    "#             filtered_assignments[\"phase_of_play\"].isin(phases_of_play)\n",
    "#         ]\n",
    "\n",
    "#     if positions is not None:\n",
    "#         filtered_assignments = filtered_assignments[\n",
    "#             filtered_assignments[\"position\"].isin(positions)\n",
    "#         ]\n",
    "\n",
    "#     filtered_run_ids = filtered_assignments[\"run_id\"].unique()\n",
    "\n",
    "#     # Set index for quick lookups\n",
    "#     bucket_pivot = bucket_pivot.set_index(\"assigned_cluster\")\n",
    "\n",
    "#     for cluster_idx in range(num_clusters):\n",
    "#         ax = axes[cluster_idx]\n",
    "#         draw_pitch(ax)\n",
    "\n",
    "#         # Find runs assigned to this cluster\n",
    "#         cluster_run_ids = assignments_zones.loc[\n",
    "#             assignments_zones[\"assigned_cluster\"] == cluster_idx, \"run_id\"\n",
    "#         ].tolist()\n",
    "\n",
    "#         # Apply filters\n",
    "#         cluster_run_ids = [\n",
    "#             rid for rid in cluster_run_ids if rid in filtered_run_ids\n",
    "#         ]\n",
    "\n",
    "#         if len(cluster_run_ids) > max_runs_per_cluster:\n",
    "#             cluster_run_ids = random.sample(cluster_run_ids, max_runs_per_cluster)\n",
    "\n",
    "#         for run_id in cluster_run_ids:\n",
    "#             run_df = final_runs_df[final_runs_df[\"run_id\"] == run_id]\n",
    "\n",
    "#             coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "#             if coords.shape[0] < 2:\n",
    "#                 continue\n",
    "\n",
    "#             resampled = resample_coords(coords, num_points=50)\n",
    "#             control_pts = fit_bezier_curve(resampled, num_control_points)\n",
    "\n",
    "#             if plot_absolute_positions:\n",
    "#                 start_pos = run_df[[\"x\", \"y\"]].values[0]\n",
    "#                 shifted_ctrl_pts = control_pts - control_pts[0] + start_pos\n",
    "#                 bezier_curve = evaluate_bezier_curve(\n",
    "#                     shifted_ctrl_pts, num_points=50\n",
    "#                 )\n",
    "#             else:\n",
    "#                 bezier_curve = evaluate_bezier_curve(\n",
    "#                     control_pts, num_points=50\n",
    "#                 )\n",
    "\n",
    "#             ax.plot(bezier_curve[:, 0], bezier_curve[:, 1], alpha=0.2, color=\"blue\")\n",
    "\n",
    "#         # Add text box with position bucket counts\n",
    "#         if cluster_idx in bucket_pivot.index:\n",
    "#             row = bucket_pivot.loc[cluster_idx]\n",
    "#             text_lines = []\n",
    "#             for bucket in [\"attacker\", \"midfielder\", \"defender\", \"sub\", \"unknown\"]:\n",
    "#                 if bucket in row and row[bucket] > 0:\n",
    "#                     text_lines.append(f\"{bucket}: {int(row[bucket])}\")\n",
    "#             text = \"\\n\".join(text_lines)\n",
    "#             ax.text(\n",
    "#                 0.5, 1.05, text,\n",
    "#                 transform=ax.transAxes,\n",
    "#                 ha=\"center\", va=\"bottom\",\n",
    "#                 fontsize=8,\n",
    "#                 bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
    "#             )\n",
    "\n",
    "#         ax.set_title(f\"Cluster {cluster_idx}\", fontsize=8)\n",
    "\n",
    "#     for i in range(num_clusters, len(axes)):\n",
    "#         axes[i].axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.suptitle(\"All Bézier Run Trajectories per Cluster (On-Pitch View)\", fontsize=16, y=1.02)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_cluster_trajectories_on_pitch(\n",
    "    final_runs_df,\n",
    "    assignments_zones,\n",
    "    cluster_control_points,\n",
    "    bucket_pivot,\n",
    "    num_control_points=4,\n",
    "    max_runs_per_cluster=30,\n",
    "    plot_absolute_positions=True,\n",
    "    start_zones=None,\n",
    "    end_zones=None,\n",
    "    phases_of_play=None,\n",
    "    positions=None,\n",
    "    use_absolute_zones=False,\n",
    "    start_zones_absolute=None,\n",
    "    end_zones_absolute=None\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    num_clusters = len(cluster_control_points)\n",
    "    fig, axes = plt.subplots(7, 10, figsize=(30, 20))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # --- FILTERING ---\n",
    "    filtered_assignments = assignments_zones.copy()\n",
    "\n",
    "    if start_zones is not None and not use_absolute_zones:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"start_zone\"].isin(start_zones)\n",
    "        ]\n",
    "\n",
    "    if end_zones is not None and not use_absolute_zones:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"end_zone\"].isin(end_zones)\n",
    "        ]\n",
    "\n",
    "    if start_zones_absolute is not None and use_absolute_zones:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"start_zone_absolute\"].isin(start_zones_absolute)\n",
    "        ]\n",
    "\n",
    "    if end_zones_absolute is not None and use_absolute_zones:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"end_zone_absolute\"].isin(end_zones_absolute)\n",
    "        ]\n",
    "\n",
    "    if phases_of_play is not None:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"phase_of_play\"].isin(phases_of_play)\n",
    "        ]\n",
    "\n",
    "    if positions is not None:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"position\"].isin(positions)\n",
    "        ]\n",
    "\n",
    "    filtered_run_ids = filtered_assignments[\"run_id\"].unique()\n",
    "\n",
    "    bucket_pivot = bucket_pivot.set_index(\"assigned_cluster\")\n",
    "\n",
    "    for cluster_idx in range(num_clusters):\n",
    "        ax = axes[cluster_idx]\n",
    "        draw_pitch(ax)\n",
    "\n",
    "        cluster_run_ids = assignments_zones.loc[\n",
    "            assignments_zones[\"assigned_cluster\"] == cluster_idx, \"run_id\"\n",
    "        ].tolist()\n",
    "\n",
    "        cluster_run_ids = [\n",
    "            rid for rid in cluster_run_ids if rid in filtered_run_ids\n",
    "        ]\n",
    "\n",
    "        if len(cluster_run_ids) > max_runs_per_cluster:\n",
    "            cluster_run_ids = random.sample(cluster_run_ids, max_runs_per_cluster)\n",
    "\n",
    "        for run_id in cluster_run_ids:\n",
    "            run_df = final_runs_df[final_runs_df[\"run_id\"] == run_id]\n",
    "\n",
    "            coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "            if coords.shape[0] < 2:\n",
    "                continue\n",
    "\n",
    "            resampled = resample_coords(coords, num_points=50)\n",
    "            control_pts = fit_bezier_curve(resampled, num_control_points)\n",
    "\n",
    "            if plot_absolute_positions:\n",
    "                start_pos = run_df[[\"x\", \"y\"]].values[0]\n",
    "                shifted_ctrl_pts = control_pts - control_pts[0] + start_pos\n",
    "                bezier_curve = evaluate_bezier_curve(\n",
    "                    shifted_ctrl_pts, num_points=50\n",
    "                )\n",
    "            else:\n",
    "                bezier_curve = evaluate_bezier_curve(\n",
    "                    control_pts, num_points=50\n",
    "                )\n",
    "\n",
    "            ax.plot(bezier_curve[:, 0], bezier_curve[:, 1], alpha=0.2, color=\"blue\")\n",
    "\n",
    "        if cluster_idx in bucket_pivot.index:\n",
    "            row = bucket_pivot.loc[cluster_idx]\n",
    "            text_lines = []\n",
    "            for bucket in [\"attacker\", \"midfielder\", \"defender\", \"sub\", \"unknown\"]:\n",
    "                if bucket in row and row[bucket] > 0:\n",
    "                    text_lines.append(f\"{bucket}: {int(row[bucket])}\")\n",
    "            text = \"\\n\".join(text_lines)\n",
    "            ax.text(\n",
    "                0.5, 1.05, text,\n",
    "                transform=ax.transAxes,\n",
    "                ha=\"center\", va=\"bottom\",\n",
    "                fontsize=8,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
    "            )\n",
    "\n",
    "        ax.set_title(f\"Cluster {cluster_idx}\", fontsize=8)\n",
    "\n",
    "    for i in range(num_clusters, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"All Bézier Run Trajectories per Cluster (On-Pitch View)\", fontsize=16, y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Define edges matching your pitch grid\n",
    "x_edges = np.linspace(-52.5, 52.5, 4)\n",
    "y_edges = np.linspace(-34, 34, 4)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Draw pitch outline\n",
    "draw_pitch(ax)\n",
    "\n",
    "zone_idx = 1\n",
    "\n",
    "# Draw zone rectangles and labels\n",
    "for y_bin in range(3):\n",
    "    for x_bin in range(3):\n",
    "        x_left = x_edges[x_bin]\n",
    "        x_right = x_edges[x_bin + 1]\n",
    "        y_bottom = y_edges[y_bin]\n",
    "        y_top = y_edges[y_bin + 1]\n",
    "\n",
    "        width = x_right - x_left\n",
    "        height = y_top - y_bottom\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_left, y_bottom),\n",
    "            width,\n",
    "            height,\n",
    "            linewidth=1,\n",
    "            edgecolor='black',\n",
    "            facecolor='lightgrey',\n",
    "            alpha=0.2\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Label in center\n",
    "        x_center = (x_left + x_right) / 2\n",
    "        y_center = (y_bottom + y_top) / 2\n",
    "\n",
    "        ax.text(\n",
    "            x_center, y_center,\n",
    "            str(zone_idx),\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            fontsize=14,\n",
    "            fontweight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "\n",
    "        zone_idx += 1\n",
    "\n",
    "ax.set_title(\"Zone Legend\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cluster_trajectories_on_pitch(\n",
    "    final_runs_df,\n",
    "    assignments_zones,\n",
    "    cluster_control_points,\n",
    "    bucket_pivot=bucket_pivot,\n",
    "    num_control_points=4,\n",
    "    max_runs_per_cluster=100,\n",
    "    plot_absolute_positions=True,\n",
    "    start_zones=None,\n",
    "    end_zones=None,  # You can specify zones like [1, 2, 3] if you want to filter\n",
    "    phases_of_play=None,\n",
    "    positions=None,\n",
    "    use_absolute_zones=True,\n",
    "    start_zones_absolute=[8,9],\n",
    "    end_zones_absolute=[8,9]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
