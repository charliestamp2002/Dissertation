{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.special import comb\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_DIR = pathlib.Path(\"tracking-compressed\")\n",
    "json_gz_paths = sorted(TRACKING_DIR.glob(\"tracking_*.json.gz\"))\n",
    "\n",
    "n_files = 1 # or set to len(json_gz_paths) to load all\n",
    "\n",
    "frames = []\n",
    "players = []\n",
    "used_match_ids = []  # <- store used match_ids here\n",
    "\n",
    "for file_idx, json_gz_path in enumerate(json_gz_paths[:n_files]):\n",
    "    match_id = json_gz_path.stem  # e.g. \"tracking_g2444470\"\n",
    "    used_match_ids.append(match_id)  # <- keep track of what's loaded\n",
    "\n",
    "    records = []\n",
    "\n",
    "    with gzip.open(json_gz_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            records.append(json.loads(line))\n",
    "\n",
    "    for r in records:\n",
    "        f_data = {\n",
    "            \"match_id\": match_id,\n",
    "            \"period\": r[\"period\"],\n",
    "            \"frameIdx\": r[\"frameIdx\"],\n",
    "            \"gameClock\": r[\"gameClock\"],\n",
    "            \"lastTouch_team\": r[\"lastTouch\"],\n",
    "            \"ball_x\": r[\"ball\"][\"xyz\"][0],\n",
    "            \"ball_y\": r[\"ball\"][\"xyz\"][1],\n",
    "            \"ball_z\": r[\"ball\"][\"xyz\"][2],\n",
    "        }\n",
    "        frames.append(f_data)\n",
    "\n",
    "        for side in [\"homePlayers\", \"awayPlayers\"]:\n",
    "            for p in r[side]:\n",
    "                px, py, pz = p[\"xyz\"]\n",
    "                players.append({\n",
    "                    \"match_id\": match_id,\n",
    "                    \"period\": r[\"period\"],\n",
    "                    \"frameIdx\": r[\"frameIdx\"],\n",
    "                    \"side\": \"home\" if side == \"homePlayers\" else \"away\",\n",
    "                    \"playerId\": p[\"playerId\"],\n",
    "                    \"optaId\": str(p[\"optaId\"]),\n",
    "                    \"number\": p[\"number\"],\n",
    "                    \"x\": px, \"y\": py, \"z\": pz,\n",
    "                    \"speed\": p[\"speed\"],\n",
    "                })\n",
    "\n",
    "# Convert to DataFrames\n",
    "frames_df = pd.DataFrame(frames)\n",
    "players_df = pd.DataFrame(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(json_gz_paths), \"files loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract suffixes like \"g2444470\" from used tracking files\n",
    "used_match_suffixes = [match_id.split(\"_\", 1)[1].replace(\".json\", \"\") for match_id in used_match_ids]\n",
    "\n",
    "# Step 2: Gather metadata file paths from both formats\n",
    "metadata_dir = pathlib.Path(\"metadata_SecondSpectrum\")\n",
    "all_metadata_files = list(metadata_dir.glob(\"*.json\"))\n",
    "\n",
    "# Build map: match_suffix (e.g., \"g2444470\") → metadata_path\n",
    "metadata_file_map = {}\n",
    "for path in all_metadata_files:\n",
    "    filename = path.name\n",
    "    if filename.startswith(\"metadata_g\") and filename.endswith(\".json\"):\n",
    "        suffix = filename.split(\"_\")[1].split(\".\")[0]  # 'g2444470'\n",
    "    elif filename.endswith(\"_SecondSpectrum_Metadata.json\"):\n",
    "        suffix = filename.split(\"_\")[0]  # 'g2444470'\n",
    "    else:\n",
    "        continue  # skip non-matching files\n",
    "    metadata_file_map[suffix] = path\n",
    "\n",
    "# Build a lookup DataFrame linking tracking suffixes to match date and teams\n",
    "tracking_meta_records = []\n",
    "for suffix, metadata_path in metadata_file_map.items():\n",
    "    with open(metadata_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        meta = json.load(f)\n",
    "    tracking_meta_records.append({\n",
    "        \"match_date\": meta.get(\"matchDate\"),\n",
    "        \"home_team\": meta.get(\"homeTeamName\"),\n",
    "        \"away_team\": meta.get(\"awayTeamName\"),\n",
    "        \"tracking_suffix\": suffix,\n",
    "        \"metadata_path\": str(metadata_path),\n",
    "    })\n",
    "\n",
    "\n",
    "# Step 3: Load metadata and build lookup for used matches\n",
    "opta_meta_lookup = {}\n",
    "\n",
    "for suffix in used_match_suffixes:\n",
    "    metadata_path = metadata_file_map.get(suffix)\n",
    "    if not metadata_path:\n",
    "        print(f\" No metadata found for match {suffix}\")\n",
    "        continue\n",
    "\n",
    "    with open(metadata_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        meta = json.load(f)\n",
    "\n",
    "    match_id = f\"tracking_{suffix}\"  # same format as tracking match_id\n",
    "\n",
    "    for side, team in [(\"homePlayers\", \"home\"), (\"awayPlayers\", \"away\")]:\n",
    "        for p in meta.get(side, []):\n",
    "            key = (match_id, str(p[\"optaId\"]))\n",
    "            opta_meta_lookup[key] = {\n",
    "                \"player_name\": p.get(\"name\"),\n",
    "                \"position\": p.get(\"position\"),\n",
    "                \"team_role\": team,\n",
    "            }\n",
    "\n",
    "print(f\" Loaded metadata for {len(opta_meta_lookup)} players.\")\n",
    "\n",
    "meta_df = pd.DataFrame([\n",
    "    {\n",
    "        \"match_id\": match_id,\n",
    "        \"optaId\": opta_id,\n",
    "        \"player_name\": info[\"player_name\"],\n",
    "        \"position\": info[\"position\"],\n",
    "        \"team_role\": info[\"team_role\"],\n",
    "    }\n",
    "    for (match_id, opta_id), info in opta_meta_lookup.items()\n",
    "])\n",
    "\n",
    "players_df[\"match_id_clean\"] = players_df[\"match_id\"].str.replace(\".json\", \"\", regex=False)\n",
    "\n",
    "# Merge using match_id and optaId as keys\n",
    "players_df = players_df.merge(\n",
    "    meta_df,\n",
    "    how=\"left\",\n",
    "    left_on=[\"match_id_clean\", \"optaId\"],\n",
    "    right_on=[\"match_id\", \"optaId\"]\n",
    ")\n",
    "\n",
    "players_df.drop(columns=[\"match_id_clean\", \"match_id_y\"], inplace=True)\n",
    "players_df.rename(columns={\"match_id_x\": \"match_id\"}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmenting Runs (across multiple matches)\n",
    "def segment_runs(players_df, speed_threshold=2.0):\n",
    "    \"\"\"\n",
    "    Segments continuous runs for each player within each match and period\n",
    "    when speed exceeds a threshold.\n",
    "    \"\"\"\n",
    "    runs = []\n",
    "    for (match_id, period, playerId), group in players_df.groupby([\"match_id\", \"period\", \"playerId\"]):\n",
    "        group = group.sort_values(\"frameIdx\")\n",
    "        current_run = []\n",
    "        for _, row in group.iterrows():\n",
    "            if row[\"speed\"] > speed_threshold:\n",
    "                current_run.append(row)\n",
    "            elif current_run:\n",
    "                runs.append(pd.DataFrame(current_run))\n",
    "                current_run = []\n",
    "        if current_run:\n",
    "            runs.append(pd.DataFrame(current_run))\n",
    "    return runs\n",
    "\n",
    "def filter_off_ball_runs_with_distance(runs_list, frames_df, players_df, min_distance=3.0):\n",
    "    \"\"\"\n",
    "    Filters runs to keep only those where:\n",
    "    - The player never touched the ball (not lastTouch)\n",
    "    - The player is always at least `min_distance` away from the ball\n",
    "    \"\"\"\n",
    "    frame_last_touch = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[\"lastTouch_team\"].to_dict()\n",
    "    ball_positions = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[[\"ball_x\", \"ball_y\"]].to_dict(\"index\")\n",
    "    \n",
    "    off_ball_runs = []\n",
    "\n",
    "    for run_df in runs_list:\n",
    "        player_id = run_df[\"playerId\"].iloc[0]\n",
    "        match_id = run_df[\"match_id\"].iloc[0]\n",
    "        period = run_df[\"period\"].iloc[0]\n",
    "        frame_idxs = run_df[\"frameIdx\"].values\n",
    "\n",
    "        is_off_ball = True\n",
    "        for frame_idx in frame_idxs:\n",
    "            key = (match_id, period, frame_idx)\n",
    "\n",
    "            # Check lastTouch\n",
    "            if frame_last_touch.get(key) == player_id:\n",
    "                is_off_ball = False\n",
    "                break\n",
    "\n",
    "            # Check distance from ball\n",
    "            ball_pos = ball_positions.get(key)\n",
    "            if ball_pos is None:\n",
    "                continue  # Skip frames with missing ball info\n",
    "\n",
    "            player_pos = run_df[run_df[\"frameIdx\"] == frame_idx][[\"x\", \"y\"]].values\n",
    "            if player_pos.size == 0:\n",
    "                continue\n",
    "\n",
    "            dist = np.linalg.norm(player_pos[0] - np.array([ball_pos[\"ball_x\"], ball_pos[\"ball_y\"]]))\n",
    "            if dist < min_distance:\n",
    "                is_off_ball = False\n",
    "                break\n",
    "\n",
    "        if is_off_ball:\n",
    "            off_ball_runs.append(run_df)\n",
    "\n",
    "    return off_ball_runs\n",
    "\n",
    "runs_list = segment_runs(players_df)\n",
    "print(f\"Total runs segmented: {len(runs_list)}\")\n",
    "\n",
    "runs_list = filter_off_ball_runs_with_distance(runs_list, frames_df, players_df, min_distance=3.0)\n",
    "print(f\"Total off-ball runs (with min distance): {len(runs_list)}\")\n",
    "\n",
    "# Annotate each run with player metadata\n",
    "annotated_runs = []\n",
    "\n",
    "for run_df in runs_list:\n",
    "    # Make a copy of the run to avoid modifying in-place\n",
    "    run_df = run_df.copy()\n",
    "\n",
    "    # Extract metadata from the first row (same for entire run)\n",
    "    meta_fields = [\"playerId\", \"optaId\", \"match_id\", \"player_name\", \"position\", \"team_role\"]\n",
    "    for field in meta_fields:\n",
    "        run_df[field] = run_df.iloc[0][field]\n",
    "\n",
    "    annotated_runs.append(run_df)\n",
    "\n",
    "# Assign a unique run_id to each run\n",
    "for i, run_df in enumerate(annotated_runs):\n",
    "    run_df[\"run_id\"] = i\n",
    "\n",
    "# Optional: Combine into one dataframe\n",
    "all_runs_df = pd.concat(annotated_runs, ignore_index=True)\n",
    "\n",
    "# Preview\n",
    "print(all_runs_df[[\"player_name\", \"position\", \"team_role\", \"x\", \"y\", \"speed\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def mirror function\n",
    "def mirror_group(group):\n",
    "\n",
    "    y_mean = group[\"y\"].mean()\n",
    "    if y_mean < 0:\n",
    "        group[\"y_mirror\"] = -group[\"y\"]\n",
    "    else:\n",
    "        group[\"y_mirror\"] = group[\"y\"]\n",
    "    group[\"x_mirror\"] = group[\"x\"]\n",
    "\n",
    "\n",
    "    return group\n",
    "\n",
    "def should_flip_x(team_role, period):\n",
    "    \"\"\"\n",
    "    Returns True if this team in this period attacks right-to-left.\n",
    "    \"\"\"\n",
    "    if period == 1:\n",
    "        return team_role == \"away\"\n",
    "    elif period == 2:\n",
    "        return team_role == \"home\"\n",
    "    else:\n",
    "        return False  # Just in case\n",
    "\n",
    "# Apply mirroring per run\n",
    "all_runs_df = all_runs_df.groupby(\"run_id\", group_keys=False).apply(mirror_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR CENTROID CALCULATION FOR PERSON PERFORMING RUN \n",
    "\n",
    "# # Precompute centroids for all frames and both teams\n",
    "# centroid_dict = {}  # (match_id, period, frameIdx, team_side) -> centroid np.array\n",
    "\n",
    "# for (match_id, period, frame_idx), group in players_df.groupby([\"match_id\", \"period\", \"frameIdx\"]):\n",
    "#     for side in [\"home\", \"away\"]:\n",
    "#         team_players = group[(group[\"side\"] == side) & (group[\"number\"] != 1)]\n",
    "#         if not team_players.empty:\n",
    "#             centroid = team_players[[\"x\", \"y\"]].mean().values\n",
    "#         else:\n",
    "#             centroid = np.array([0.0, 0.0])\n",
    "#         centroid_dict[(match_id, period, frame_idx, side)] = centroid\n",
    "\n",
    "# # Precompute playerId → side map for each (match_id, period, frameIdx)\n",
    "# player_side_lookup = players_df.set_index([\"match_id\", \"period\", \"frameIdx\", \"playerId\"])[\"side\"].to_dict()\n",
    "\n",
    "# # Convert frames_df for fast access to lastTouch per frame\n",
    "# frame_last_touch = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[\"lastTouch\"].to_dict()\n",
    "\n",
    "# adjusted_runs_list = []\n",
    "\n",
    "# # Now adjust each run\n",
    "# for run_df in runs_list:\n",
    "#     run_df = run_df.sort_values(\"frameIdx\")\n",
    "#     match_id = run_df[\"match_id\"].iloc[0]\n",
    "#     period = run_df[\"period\"].iloc[0]\n",
    "#     start_frame = run_df[\"frameIdx\"].iloc[0]\n",
    "\n",
    "#     team_centroid = np.array([0.0, 0.0])  # fallback\n",
    "\n",
    "#     key = (match_id, period, start_frame)\n",
    "#     first_player = run_df[\"playerId\"].iloc[0]\n",
    "#     side = player_side_lookup.get((match_id, period, start_frame, first_player))\n",
    "\n",
    "#     if side is not None:\n",
    "#         team_centroid = centroid_dict.get((match_id, period, start_frame, side), team_centroid)\n",
    "\n",
    "#     run_df[\"x_c\"] = run_df[\"x\"] - team_centroid[0]\n",
    "#     run_df[\"y_c\"] = run_df[\"y\"] - team_centroid[1]\n",
    "#     run_df[\"x_mirror_c\"] = run_df[\"x_mirror\"] - team_centroid[0]\n",
    "#     run_df[\"y_mirror_c\"] = run_df[\"y_mirror\"] - team_centroid[1]\n",
    "\n",
    "#     adjusted_runs_list.append(run_df)\n",
    "\n",
    "# THIS IS FOR CENTROID CALCULATION ACCORDING TO WHOMEVER IS IN POSSESSION\n",
    "\n",
    "# # Precompute centroids for all frames and both teams\n",
    "# centroid_dict = {}  # (match_id, period, frameIdx, team_side) -> centroid np.array\n",
    "\n",
    "# for (match_id, period, frame_idx), group in players_df.groupby([\"match_id\", \"period\", \"frameIdx\"]):\n",
    "#     for side in [\"home\", \"away\"]:\n",
    "#         team_players = group[(group[\"side\"] == side) & (group[\"number\"] != 1)]\n",
    "#         if not team_players.empty:\n",
    "#             centroid = team_players[[\"x\", \"y\"]].mean().values\n",
    "#         else:\n",
    "#             centroid = np.array([0.0, 0.0])\n",
    "#         centroid_dict[(match_id, period, frame_idx, side)] = centroid\n",
    "\n",
    "# # Precompute playerId → side map for each (match_id, period, frameIdx)\n",
    "# player_side_lookup = players_df.set_index([\"match_id\", \"period\", \"frameIdx\", \"playerId\"])[\"side\"].to_dict()\n",
    "\n",
    "# # Convert frames_df for fast access to lastTouch per frame\n",
    "# frame_last_touch = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[\"lastTouch\"].to_dict()\n",
    "\n",
    "# adjusted_runs_list = []\n",
    "\n",
    "# grouped = all_runs_df.groupby([\"match_id\", \"period\", \"playerId\", \"run_id\"])  # assuming you added a unique run_id\n",
    "\n",
    "# for _, run_df in grouped:\n",
    "#     run_df = run_df.sort_values(\"frameIdx\")\n",
    "#     match_id = run_df[\"match_id\"].iloc[0]\n",
    "#     match_id = match_id.replace(\".json\", \"\")\n",
    "#     period = run_df[\"period\"].iloc[0]\n",
    "#     start_frame = run_df[\"frameIdx\"].iloc[0]\n",
    "\n",
    "#     team_centroid = np.array([0.0, 0.0])  # fallback if no possession info\n",
    "\n",
    "\n",
    "#     key = (match_id, period, start_frame)\n",
    "#     if key not in centroid_dict:\n",
    "#         print(\"Missing key:\", key)\n",
    "#     last_touch_player = frame_last_touch.get(key)\n",
    "\n",
    "#     if last_touch_player is not None:\n",
    "#         possession_side = player_side_lookup.get((match_id, period, start_frame, last_touch_player))\n",
    "#         if possession_side is not None:\n",
    "#             team_centroid = centroid_dict.get((match_id, period, start_frame, possession_side), team_centroid)\n",
    "    \n",
    "#     print(team_centroid)\n",
    "\n",
    "#     run_df[\"x_c\"] = run_df[\"x\"] - team_centroid[0]\n",
    "#     run_df[\"y_c\"] = run_df[\"y\"] - team_centroid[1]\n",
    "#     run_df[\"x_mirror_c\"] = run_df[\"x_mirror\"] - team_centroid[0]\n",
    "#     run_df[\"y_mirror_c\"] = run_df[\"y_mirror\"] - team_centroid[1]\n",
    "\n",
    "#     adjusted_runs_list.append(run_df)\n",
    "\n",
    "# # Combine into a final DataFrame\n",
    "# final_runs_df = pd.concat(adjusted_runs_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Precompute centroids for all frames and both teams (excluding goalkeeper)\n",
    "players_df[\"number\"] = players_df[\"number\"].astype(int)\n",
    "\n",
    "centroid_dict = {}\n",
    "for (match_id, period, frame_idx), group in players_df.groupby([\"match_id\", \"period\", \"frameIdx\"]):\n",
    "    for side in [\"home\", \"away\"]:\n",
    "        team_players = group[(group[\"side\"] == side) & (group[\"number\"] != 1)]\n",
    "        centroid = team_players[[\"x\", \"y\"]].mean().values if not team_players.empty else np.array([0.0, 0.0])\n",
    "        centroid_dict[(match_id, period, frame_idx, side)] = centroid\n",
    "\n",
    "print(f\"Centroids computed for {len(centroid_dict)} frame-side combinations.\")\n",
    "print(list(centroid_dict.items())[:5])  # show first few for inspection\n",
    "\n",
    "#print(centroid_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lastTouch and player-side lookups\n",
    "frame_last_touch_team = frames_df.set_index([\"match_id\", \"period\", \"frameIdx\"])[\"lastTouch_team\"].to_dict()\n",
    "player_side_lookup = players_df.set_index([\"match_id\", \"period\", \"frameIdx\", \"playerId\"])[\"side\"].to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_runs_list = []\n",
    "\n",
    "grouped = all_runs_df.groupby([\"match_id\", \"period\", \"playerId\", \"run_id\"], group_keys=False)\n",
    "\n",
    "for _, run_df in grouped:\n",
    "    run_df = run_df.sort_values(\"frameIdx\")\n",
    "    match_id = run_df[\"match_id\"].iloc[0]\n",
    "    period = run_df[\"period\"].iloc[0]\n",
    "    start_frame = run_df[\"frameIdx\"].iloc[0]\n",
    "\n",
    "    team_centroid = np.array([0.0, 0.0])  # fallback default\n",
    "\n",
    "    key = (match_id, period, start_frame)\n",
    "    possession_side = frame_last_touch_team.get(key)\n",
    "\n",
    "    team_role = run_df[\"team_role\"].iloc[0]\n",
    "\n",
    "    if possession_side is None: \n",
    "        in_possession = np.nan\n",
    "        phase_of_play = np.nan\n",
    "    else: \n",
    "        in_possession = (team_role == possession_side)\n",
    "        phase_of_play = \"attack\" if in_possession else \"defend\" \n",
    "\n",
    "    run_df[\"in_possession\"] = in_possession\n",
    "    run_df[\"phase_of_play\"] = phase_of_play\n",
    "\n",
    "    # if possession_side is not None:\n",
    "    #     team_centroid = centroid_dict.get((match_id, period, start_frame, possession_side), team_centroid)\n",
    "\n",
    "    # Always compute centroid for this player's own team. As opposed to above where we used possession side.\n",
    "    team_centroid = centroid_dict.get(\n",
    "        (match_id, period, start_frame, team_role),\n",
    "        np.array([0.0, 0.0])\n",
    "    )\n",
    "\n",
    "    #print(team_centroid)\n",
    "\n",
    "    run_df[\"x_c\"] = run_df[\"x\"] - team_centroid[0]\n",
    "    run_df[\"y_c\"] = run_df[\"y\"] - team_centroid[1]\n",
    "    run_df[\"x_mirror_c\"] = run_df[\"x_mirror\"] - team_centroid[0]\n",
    "    run_df[\"y_mirror_c\"] = run_df[\"y_mirror\"] - team_centroid[1]\n",
    "\n",
    "    flip_x = should_flip_x(team_role, period)\n",
    "    if flip_x:\n",
    "        run_df[\"x_mirror\"] = -run_df[\"x_mirror\"]\n",
    "        run_df[\"x_mirror_c\"] = -run_df[\"x_mirror_c\"]\n",
    "\n",
    "    adjusted_runs_list.append(run_df)\n",
    "\n",
    "final_runs_df = pd.concat(adjusted_runs_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(final_runs_df[\"x_mirror_c\"], bins=500, alpha=0.4, label=\"x_mirror_c\")\n",
    "plt.hist(final_runs_df[\"x\"], bins=500, alpha=0.4, label=\"x\")\n",
    "plt.hist(final_runs_df[\"x_c\"], bins=500, alpha=0.4, label=\"x_c\")\n",
    "plt.hist(final_runs_df[\"x_mirror\"], bins=500, alpha=0.4, label=\"x_mirror\")\n",
    "plt.title(\"Distribution of x_mirror_c, x, x_c, and x_mirror\")\n",
    "plt.xlabel(\"Position (x-axis)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(final_runs_df[\"y_mirror_c\"], bins=500, alpha=0.4, label=\"y_mirror_c\")\n",
    "plt.hist(final_runs_df[\"y\"], bins=500, alpha=1.0, label=\"y\")\n",
    "plt.hist(final_runs_df[\"y_c\"], bins=500, alpha=0.4, label=\"y_c\")\n",
    "plt.hist(final_runs_df[\"y_mirror\"], bins=500, alpha=0.4, label=\"y_mirror\")\n",
    "plt.title(\"Distribution of y_mirror_c, y, y_c, and y_mirror\")\n",
    "plt.xlabel(\"Position (y-axis)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_ball_carrier_df(run_df, frames_df, players_df, frame_last_touch_team):\n",
    "#     \"\"\"\n",
    "#     For a given run_df, extracts ball carrier positions for the same team\n",
    "#     during the frames of the run.\n",
    "#     Returns:\n",
    "#         ball_carrier_df or None\n",
    "#     \"\"\"\n",
    "#     match_id = run_df[\"match_id\"].iloc[0]\n",
    "#     period = run_df[\"period\"].iloc[0]\n",
    "#     team_role = run_df[\"team_role\"].iloc[0]\n",
    "#     frames = run_df[\"frameIdx\"].values\n",
    "\n",
    "#     carrier_rows = []\n",
    "\n",
    "#     for f in frames:\n",
    "#         key = (match_id, period, f)\n",
    "#         last_touch_side = frame_last_touch_team.get(key)\n",
    "\n",
    "#         if last_touch_side != team_role:\n",
    "#             # Ball not possessed by same team\n",
    "#             continue\n",
    "\n",
    "#         # Get ball position\n",
    "#         ball_row = frames_df[\n",
    "#             (frames_df[\"match_id\"] == match_id) &\n",
    "#             (frames_df[\"period\"] == period) &\n",
    "#             (frames_df[\"frameIdx\"] == f)\n",
    "#         ]\n",
    "\n",
    "#         if ball_row.empty:\n",
    "#             continue\n",
    "\n",
    "#         ball_x = ball_row[\"ball_x\"].values[0]\n",
    "#         ball_y = ball_row[\"ball_y\"].values[0]\n",
    "\n",
    "#         # Get team players\n",
    "#         team_players = players_df[\n",
    "#             (players_df[\"match_id\"] == match_id) &\n",
    "#             (players_df[\"period\"] == period) &\n",
    "#             (players_df[\"frameIdx\"] == f) &\n",
    "#             (players_df[\"side\"] == team_role)\n",
    "#         ]\n",
    "\n",
    "#         if team_players.empty:\n",
    "#             continue\n",
    "\n",
    "#         team_players = team_players.copy()\n",
    "#         team_players[\"dist_to_ball\"] = np.linalg.norm(\n",
    "#             team_players[[\"x\", \"y\"]].values - np.array([[ball_x, ball_y]]), axis=1\n",
    "#         )\n",
    "#         carrier_row = team_players.loc[team_players[\"dist_to_ball\"].idxmin()]\n",
    "#         carrier_rows.append(carrier_row)\n",
    "\n",
    "#     if carrier_rows:\n",
    "#         ball_carrier_df = pd.DataFrame(carrier_rows)\n",
    "#         return ball_carrier_df\n",
    "#     else:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Different Types of Tactical Runs:\n",
    "\n",
    "## Overlapping Runs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_ball_carrier_df_fast(run_df, players_with_ball_df):\n",
    "    \"\"\"\n",
    "    Fast version of extract_ball_carrier_df.\n",
    "    \"\"\"\n",
    "    match_id = run_df[\"match_id\"].iloc[0]\n",
    "    period = run_df[\"period\"].iloc[0]\n",
    "    team_role = run_df[\"team_role\"].iloc[0]\n",
    "    frames = run_df[\"frameIdx\"].unique()\n",
    "\n",
    "    # Slice relevant frames for this run\n",
    "    run_players = players_with_ball_df[\n",
    "        (players_with_ball_df[\"match_id\"] == match_id) &\n",
    "        (players_with_ball_df[\"period\"] == period) &\n",
    "        (players_with_ball_df[\"frameIdx\"].isin(frames))\n",
    "    ]\n",
    "\n",
    "    # Keep only teammates\n",
    "    teammates = run_players[\n",
    "        run_players[\"side\"] == team_role\n",
    "    ].copy()\n",
    "\n",
    "    if teammates.empty:\n",
    "        return None\n",
    "\n",
    "    # Compute distance to ball\n",
    "    teammates[\"dist_to_ball\"] = np.linalg.norm(\n",
    "        teammates[[\"x\", \"y\"]].values - teammates[[\"ball_x\", \"ball_y\"]].values,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Find closest player in each frame\n",
    "    idx_min_dist = teammates.groupby(\"frameIdx\")[\"dist_to_ball\"].idxmin()\n",
    "\n",
    "    ball_carrier_df = teammates.loc[idx_min_dist]\n",
    "\n",
    "    if ball_carrier_df.empty:\n",
    "        return None\n",
    "    else:\n",
    "        return ball_carrier_df\n",
    "\n",
    "def is_overlapping_run(run_df, ball_carrier_df, min_pass_distance=5.0):\n",
    "    \"\"\"\n",
    "    Checks if a run overlaps the ball carrier.\n",
    "    Skips runs if the ball carrier changes during the run.\n",
    "    \"\"\"\n",
    "    if ball_carrier_df is None:\n",
    "        return False\n",
    "\n",
    "    # Check how many unique carriers there were during this run\n",
    "    unique_carriers = ball_carrier_df[\"playerId\"].nunique()\n",
    "    # Can look at subRuns later, but for now we assume one carrier per run\n",
    "    if unique_carriers > 1:\n",
    "        # Carrier changed mid-run; skip for safety\n",
    "        return False\n",
    "\n",
    "    # Proceed as before\n",
    "    f_start = run_df[\"frameIdx\"].iloc[0]\n",
    "    f_end = run_df[\"frameIdx\"].iloc[-1]\n",
    "\n",
    "    runner_start = run_df.iloc[0][[\"x\", \"y\"]].values\n",
    "    runner_end = run_df.iloc[-1][[\"x\", \"y\"]].values\n",
    "\n",
    "    carrier_start_row = ball_carrier_df.loc[\n",
    "        ball_carrier_df[\"frameIdx\"] == f_start\n",
    "    ]\n",
    "\n",
    "    carrier_end_row = ball_carrier_df.loc[\n",
    "        ball_carrier_df[\"frameIdx\"] == f_end\n",
    "    ]\n",
    "\n",
    "    if carrier_start_row.empty or carrier_end_row.empty:\n",
    "        return False\n",
    "\n",
    "    carrier_start = carrier_start_row.iloc[0][[\"x\", \"y\"]].values\n",
    "    carrier_end = carrier_end_row.iloc[0][[\"x\", \"y\"]].values\n",
    "\n",
    "    # Compute lateral offset (y-direction)\n",
    "    delta_start_y = runner_start[1] - carrier_start[1]\n",
    "    delta_end_y = runner_end[1] - carrier_end[1]\n",
    "\n",
    "    # Check if runner switched sides outside the carrier\n",
    "    overlap_side_change = np.sign(delta_start_y) != np.sign(delta_end_y)\n",
    "\n",
    "    # Check lateral distance threshold\n",
    "    lateral_movement = abs(delta_end_y - delta_start_y)\n",
    "\n",
    "    # Ensure overlap moves forward enough\n",
    "    forward_distance = runner_end[0] - runner_start[0]\n",
    "\n",
    "    return (\n",
    "        overlap_side_change and\n",
    "        lateral_movement > 2.0 and\n",
    "        forward_distance > min_pass_distance\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underlapping Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_underlapping_run(run_df, ball_carrier_df, min_pass_distance=5.0):\n",
    "    \"\"\"\n",
    "    Heuristic: detects underlapping runs where the runner cuts inside\n",
    "    relative to the ball carrier.\n",
    "\n",
    "    Returns True only if the ball carrier remains constant during the run.\n",
    "    \"\"\"\n",
    "    if ball_carrier_df is None:\n",
    "        return False\n",
    "\n",
    "    # Check how many unique carriers there were during this run\n",
    "    unique_carriers = ball_carrier_df[\"playerId\"].nunique()\n",
    "    if unique_carriers > 1:\n",
    "        # Carrier changed mid-run; skip for safety\n",
    "        return False\n",
    "\n",
    "    # Proceed as before\n",
    "    f_start = run_df[\"frameIdx\"].iloc[0]\n",
    "    f_end = run_df[\"frameIdx\"].iloc[-1]\n",
    "\n",
    "    runner_start = run_df.iloc[0][[\"x\", \"y\"]].values\n",
    "    runner_end = run_df.iloc[-1][[\"x\", \"y\"]].values\n",
    "\n",
    "    carrier_start_row = ball_carrier_df.loc[\n",
    "        ball_carrier_df[\"frameIdx\"] == f_start\n",
    "    ]\n",
    "\n",
    "    carrier_end_row = ball_carrier_df.loc[\n",
    "        ball_carrier_df[\"frameIdx\"] == f_end\n",
    "    ]\n",
    "\n",
    "    if carrier_start_row.empty or carrier_end_row.empty:\n",
    "        return False\n",
    "\n",
    "    carrier_start = carrier_start_row.iloc[0][[\"x\", \"y\"]].values\n",
    "    carrier_end = carrier_end_row.iloc[0][[\"x\", \"y\"]].values\n",
    "\n",
    "    # Compute lateral offsets (y-difference)\n",
    "    delta_start_y = runner_start[1] - carrier_start[1]\n",
    "    delta_end_y = runner_end[1] - carrier_end[1]\n",
    "\n",
    "    overlap_side_change = np.sign(delta_start_y) != np.sign(delta_end_y)\n",
    "\n",
    "    lateral_distance_start = abs(delta_start_y)\n",
    "    lateral_distance_end = abs(delta_end_y)\n",
    "\n",
    "    lateral_movement = lateral_distance_start - lateral_distance_end\n",
    "\n",
    "    forward_distance = runner_end[0] - runner_start[0]\n",
    "\n",
    "    # For underlap:\n",
    "    # - sign change\n",
    "    # - lateral distance reduced (runner cuts inside)\n",
    "    # - forward enough\n",
    "    return (\n",
    "        overlap_side_change\n",
    "        and lateral_movement > 1.0\n",
    "        and forward_distance > min_pass_distance\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagonal Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_diagonal_run(run_df, min_length=5.0, angle_min=20, angle_max=70):\n",
    "    \"\"\"\n",
    "    Heuristic to detect diagonal runs.\n",
    "\n",
    "    - Checks total length\n",
    "    - Checks that the angle lies within a diagonal corridor\n",
    "\n",
    "    Returns True if diagonal.\n",
    "    \"\"\"\n",
    "    # Start and end positions\n",
    "    runner_start = run_df.iloc[0][[\"x\", \"y\"]].values\n",
    "    runner_end = run_df.iloc[-1][[\"x\", \"y\"]].values\n",
    "\n",
    "    delta_x = runner_end[0] - runner_start[0]\n",
    "    delta_y = runner_end[1] - runner_start[1]\n",
    "\n",
    "    # Total run distance\n",
    "    total_distance = np.linalg.norm([delta_x, delta_y])\n",
    "    if total_distance < min_length:\n",
    "        return False\n",
    "\n",
    "    # Compute angle in degrees\n",
    "    angle_deg = np.degrees(np.arctan2(delta_y, delta_x))\n",
    "\n",
    "    abs_angle = abs(angle_deg)\n",
    "\n",
    "    # Check if angle is in diagonal corridor\n",
    "    return angle_min <= abs_angle <= angle_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid\n",
    "x_edges = np.linspace(-52.5, 52.5, 4)   # splits pitch length into thirds\n",
    "y_edges = np.linspace(-34, 34, 4)       # splits width into thirds\n",
    "\n",
    "def get_zone(x, y, x_edges, y_edges):\n",
    "    x_bin = np.digitize([x], x_edges)[0] - 1\n",
    "    y_bin = np.digitize([y], y_edges)[0] - 1\n",
    "    x_bin = min(max(x_bin, 0), len(x_edges)-2)\n",
    "    y_bin = min(max(y_bin, 0), len(y_edges)-2)\n",
    "    zone_idx = y_bin * (len(x_edges)-1) + x_bin + 1\n",
    "    return zone_idx\n",
    "\n",
    "# Build players_with_ball_df ONCE for all runs\n",
    "players_with_ball_df = players_df.merge(\n",
    "    frames_df[[\"match_id\", \"period\", \"frameIdx\", \"ball_x\", \"ball_y\", \"lastTouch_team\"]],\n",
    "    on=[\"match_id\", \"period\", \"frameIdx\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_ball\")\n",
    ")\n",
    "\n",
    "zone_records = []\n",
    "\n",
    "for run_id, run_df in final_runs_df.groupby(\"run_id\"):\n",
    "\n",
    "    # Mirrored & centered positions\n",
    "    start_x_mirror_c = run_df[\"x_mirror_c\"].iloc[0]\n",
    "    start_y_mirror_c = run_df[\"y_mirror_c\"].iloc[0]\n",
    "\n",
    "    end_x_mirror_c = run_df[\"x_mirror_c\"].iloc[-1]\n",
    "    end_y_mirror_c = run_df[\"y_mirror_c\"].iloc[-1]\n",
    "\n",
    "    coords = run_df[[\"x\", \"y\"]].values\n",
    "\n",
    "    if coords.shape[0] < 2:\n",
    "        run_length = 0.0\n",
    "    else: \n",
    "        deltas = np.diff(coords, axis=0)\n",
    "        segment_lengths = np.linalg.norm(deltas, axis=1)\n",
    "        run_length = np.sum(segment_lengths)\n",
    "\n",
    "    mean_speed = run_df[\"speed\"].mean()\n",
    "    max_speed = run_df[\"speed\"].max()\n",
    "\n",
    "    dx = end_x_mirror_c - start_x_mirror_c\n",
    "    dy = end_y_mirror_c - start_y_mirror_c\n",
    "\n",
    "    run_angle_rad = np.arctan2(dy, dx)\n",
    "    run_angle_deg = np.degrees(run_angle_rad)\n",
    "\n",
    "    run_forward = dx > 0  # True if run is forward (right side of pitch)\n",
    "    \n",
    "    start_zone = get_zone(start_x_mirror_c, start_y_mirror_c, x_edges, y_edges)\n",
    "    end_zone = get_zone(end_x_mirror_c, end_y_mirror_c, x_edges, y_edges)\n",
    "\n",
    "    # Absolute pitch positions\n",
    "    start_x_abs = run_df[\"x\"].iloc[0]\n",
    "    start_y_abs = run_df[\"y\"].iloc[0]\n",
    "\n",
    "    end_x_abs = run_df[\"x\"].iloc[-1]\n",
    "    end_y_abs = run_df[\"y\"].iloc[-1]\n",
    "\n",
    "    start_zone_abs = get_zone(start_x_abs, start_y_abs, x_edges, y_edges)\n",
    "    end_zone_abs = get_zone(end_x_abs, end_y_abs, x_edges, y_edges)\n",
    "\n",
    "    phase_of_play = run_df[\"phase_of_play\"].iloc[0]\n",
    "    in_possession = run_df[\"in_possession\"].iloc[0]\n",
    "    team_role = run_df[\"team_role\"].iloc[0]\n",
    "    position = run_df[\"position\"].iloc[0]\n",
    "\n",
    "    # Extract ball carrier df\n",
    "    ball_carrier_df = extract_ball_carrier_df_fast(\n",
    "        run_df, players_with_ball_df\n",
    "    )\n",
    "    \n",
    "    # Check overlapping run\n",
    "    overlapping = is_overlapping_run(run_df, ball_carrier_df)\n",
    "    underlapping = is_underlapping_run(run_df, ball_carrier_df)\n",
    "    is_diag = is_diagonal_run(run_df)\n",
    "\n",
    "    zone_records.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"start_zone\": start_zone,\n",
    "        \"end_zone\": end_zone,\n",
    "        \"start_zone_absolute\": start_zone_abs,\n",
    "        \"end_zone_absolute\": end_zone_abs,\n",
    "        \"phase_of_play\": phase_of_play,\n",
    "        \"in_possession\": in_possession,\n",
    "        \"team_role\": team_role,\n",
    "        \"position\": position,\n",
    "        \"run_length_m\": run_length,\n",
    "        \"mean_speed\": mean_speed,\n",
    "        \"max_speed\": max_speed,\n",
    "        \"run_angle_deg\": run_angle_deg,\n",
    "        \"run_forward\": run_forward,\n",
    "        \"tactical_overlap\": overlapping,\n",
    "        \"tactical_underlap\": underlapping,\n",
    "        \"tactical_diagonal\": is_diag\n",
    "    })\n",
    "\n",
    "zones_df = pd.DataFrame(zone_records)\n",
    "print(zones_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equation (5): Bézier basis function\n",
    "def bernstein_poly(p, P, t):\n",
    "    return comb(P - 1, p) * (t**p) * ((1 - t)**(P - 1 - p))\n",
    "\n",
    "# Equation (7): Design matrix for Bézier fitting\n",
    "def bezier_design_matrix(num_points, num_control_points):\n",
    "    t_vals = np.linspace(0, 1, num_points)\n",
    "    X = np.stack([bernstein_poly(p, num_control_points, t_vals) for p in range(num_control_points)], axis=1)\n",
    "    return X  # shape: [num_points, num_control_points]\n",
    "\n",
    "# Equation (6): Fit Bézier curve via least squares\n",
    "def fit_bezier_curve(coords, num_control_points):\n",
    "    \"\"\"\n",
    "    coords: shape [N, 2] — sequence of (x, y) points\n",
    "    returns: control_points [P, 2]\n",
    "    \"\"\"\n",
    "    N = coords.shape[0]\n",
    "    X = bezier_design_matrix(N, num_control_points)  # shape [N, P]\n",
    "    \n",
    "    # Solve least squares for x and y separately\n",
    "    theta_x, _, _, _ = np.linalg.lstsq(X, coords[:, 0], rcond=None)\n",
    "    theta_y, _, _, _ = np.linalg.lstsq(X, coords[:, 1], rcond=None)\n",
    "    \n",
    "    control_points = np.stack([theta_x, theta_y], axis=1)  # shape: [P, 2]\n",
    "    return control_points\n",
    "\n",
    "# Equation (4): Evaluate Bézier curve at t using control points θ\n",
    "def evaluate_bezier_curve(control_points, num_points=50):\n",
    "    \"\"\"\n",
    "    Returns sampled points along the Bézier curve.\n",
    "    \"\"\"\n",
    "    P = control_points.shape[0]\n",
    "    X = bezier_design_matrix(num_points, P)  # shape [num_points, P]\n",
    "    curve = X @ control_points  # shape: [num_points, 2]\n",
    "    return curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_coords(coords, num_points=50):\n",
    "    from scipy.interpolate import interp1d\n",
    "    if len(coords) < 2:\n",
    "        return np.tile(coords[0], (num_points, 1))  # Edge case\n",
    "    distances = np.cumsum(np.linalg.norm(np.diff(coords, axis=0), axis=1))\n",
    "    distances = np.insert(distances, 0, 0.0)\n",
    "    total_length = distances[-1]\n",
    "    if total_length == 0:\n",
    "        return np.tile(coords[0], (num_points, 1))\n",
    "    normalized_dist = distances / total_length\n",
    "    interp_func = interp1d(normalized_dist, coords, axis=0, kind='linear')\n",
    "    uniform_dist = np.linspace(0, 1, num_points)\n",
    "    return interp_func(uniform_dist)\n",
    "\n",
    "def compute_l1_distance(traj, bezier_curve):\n",
    "    \"\"\"\n",
    "    traj, bezier_curve: both of shape [num_points, 2]\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(traj - bezier_curve))  # L1 averaged over all points and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 1 # only 1 iteration for now (for debugging)\n",
    "tolerance = 1e-3  # Minimum improvement in objective to continue\n",
    "num_points = 50\n",
    "num_control_points = 4\n",
    "k_clusters = 70\n",
    "\n",
    "# Initialize cluster centers (Bézier curves)\n",
    "random.seed(42)\n",
    "initial_centroids = random.sample(adjusted_runs_list, k_clusters)\n",
    "cluster_control_points = []\n",
    "\n",
    "for run in initial_centroids:\n",
    "    coords = run[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "    control_pts = fit_bezier_curve(coords, num_control_points)\n",
    "    cluster_control_points.append(control_pts)\n",
    "\n",
    "cluster_control_points = np.array(cluster_control_points)\n",
    "previous_objective = float('inf')\n",
    "\n",
    "for it in range(max_iterations):\n",
    "    # Assignment step\n",
    "    assignments = []\n",
    "    objective_distances = []\n",
    "\n",
    "    for run_id, run_df in final_runs_df.groupby(\"run_id\"):\n",
    "        coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "        # resampled_coords = resample_coords(coords, num_points=num_points)\n",
    "\n",
    "        resampled_coords = resample_coords(coords, num_points=num_points)\n",
    "        if resampled_coords is None:\n",
    "            continue  # skip bad run\n",
    "\n",
    "        min_dist = float(\"inf\")\n",
    "        assigned_cluster = -1\n",
    "\n",
    "        for cluster_idx, control_pts in enumerate(cluster_control_points):\n",
    "            bezier_curve = evaluate_bezier_curve(control_pts, num_points=num_points)\n",
    "            dist = compute_l1_distance(resampled_coords, bezier_curve)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                assigned_cluster = cluster_idx\n",
    "\n",
    "        # assignments.append(assigned_cluster)\n",
    "\n",
    "            # Save metadata + cluster assignment\n",
    "        assignments.append({\n",
    "            \"run_id\": run_id,\n",
    "            \"assigned_cluster\": assigned_cluster,\n",
    "            \"min_distance\": min_dist,\n",
    "            \"playerId\": run_df[\"playerId\"].iloc[0],\n",
    "            \"player_name\": run_df[\"player_name\"].iloc[0],\n",
    "            \"position\": run_df[\"position\"].iloc[0],\n",
    "            \"team_role\": run_df[\"team_role\"].iloc[0],\n",
    "            \"match_id\": run_df[\"match_id\"].iloc[0],\n",
    "        })\n",
    "\n",
    "        assignments_df = pd.DataFrame(assignments)\n",
    "\n",
    "        #print(assignments_df.head())\n",
    "\n",
    "        objective_distances.append(min_dist)\n",
    "\n",
    "    objective = np.mean(objective_distances)\n",
    "    print(f\"Iteration {it}: Mean objective = {objective:.4f}\")\n",
    "\n",
    "    # Check for convergence\n",
    "    improvement = previous_objective - objective\n",
    "    if improvement < tolerance:\n",
    "        print(f\"Converged (Δ={improvement:.6f}) at iteration {it}\")\n",
    "        break\n",
    "    previous_objective = objective\n",
    "\n",
    "    # Update step\n",
    "    new_cluster_control_points = []\n",
    "\n",
    "    for cluster_idx in range(k_clusters):\n",
    "        #assigned_indices = [i for i, a in enumerate(assignments) if a == cluster_idx]\n",
    "        assigned_indices = [i for i, a in enumerate(assignments) if a[\"assigned_cluster\"] == cluster_idx]\n",
    "        if not assigned_indices:\n",
    "            new_cluster_control_points.append(cluster_control_points[cluster_idx])\n",
    "            continue\n",
    "\n",
    "        cluster_coords = []\n",
    "        for idx in assigned_indices:\n",
    "            run_id = assignments_df.loc[idx, \"run_id\"]\n",
    "            #run_df = all_runs_df[all_runs_df[\"run_id\"] == run_id]\n",
    "            run_df = final_runs_df[final_runs_df[\"run_id\"] == run_id]\n",
    "\n",
    "            coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "            resampled = resample_coords(coords, num_points=num_points)\n",
    "            # cluster_coords.append(resampled)\n",
    "            if resampled is not None:\n",
    "                cluster_coords.append(resampled)\n",
    "\n",
    "        cluster_coords = np.stack(cluster_coords, axis=0)\n",
    "        mean_coords = np.mean(cluster_coords, axis=0)\n",
    "        new_control_pts = fit_bezier_curve(mean_coords, num_control_points)\n",
    "        new_cluster_control_points.append(new_control_pts)\n",
    "\n",
    "    cluster_control_points = np.array(new_cluster_control_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build assignments DataFrame\n",
    "assignments_df = pd.DataFrame(assignments)\n",
    "\n",
    "assignments_zones = assignments_df.merge(\n",
    "    zones_df,\n",
    "    on=\"run_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Drop duplicates\n",
    "assignments_zones.drop(columns=[\n",
    "    \"position_y\",\n",
    "    \"team_role_y\"\n",
    "], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Rename x columns back to plain names\n",
    "assignments_zones.rename(columns={\n",
    "    \"position_x\": \"position\",\n",
    "    \"team_role_x\": \"team_role\",\n",
    "}, inplace=True)\n",
    "\n",
    "# Count number of runs per position per cluster\n",
    "position_detail_counts = (\n",
    "    assignments_zones\n",
    "    .groupby([\"assigned_cluster\", \"position\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"num_runs\")\n",
    "    .sort_values([\"assigned_cluster\", \"num_runs\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "position_pivot = (\n",
    "    position_detail_counts\n",
    "    .pivot_table(index=\"assigned_cluster\",\n",
    "                 columns=\"position\",\n",
    "                 values=\"num_runs\",\n",
    "                 fill_value=0)\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering for specific positions: \n",
    "\n",
    "filter only LB runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_runs = assignments_zones[assignments_zones[\"position\"] == \"LB\"]\n",
    "\n",
    "print(lb_runs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want only clusters containing LB runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_clusters = lb_runs[\"assigned_cluster\"].unique()\n",
    "print(\"Clusters with LB runs:\", lb_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep first row of each run\n",
    "runs_meta_df = final_runs_df.groupby(\"run_id\", as_index=False).first()\n",
    "\n",
    "# Merge metadata into assignments\n",
    "merged_df = assignments_df.merge(\n",
    "    runs_meta_df,\n",
    "    on=\"run_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Clean up columns\n",
    "merged_df.drop(columns=[\n",
    "    \"position_y\",\n",
    "    \"player_name_y\",\n",
    "    \"team_role_y\",\n",
    "    \"match_id_y\",\n",
    "    \"playerId_y\",\n",
    "], inplace=True, errors=\"ignore\")\n",
    "\n",
    "merged_df.rename(columns={\n",
    "    \"player_name_x\": \"player_name\",\n",
    "    \"position_x\": \"position\",\n",
    "    \"team_role_x\": \"team_role\",\n",
    "    \"match_id_x\": \"match_id\",\n",
    "    \"playerId_x\": \"playerId\",\n",
    "}, inplace=True)\n",
    "\n",
    "#print(\"merged_df columns:\", merged_df.columns)\n",
    "\n",
    "# Group and count\n",
    "position_counts = (\n",
    "    merged_df\n",
    "    .groupby([\"assigned_cluster\", \"position\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"num_runs\")\n",
    "    .sort_values([\"assigned_cluster\", \"num_runs\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "#print(position_counts.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_positions = merged_df[\"position\"].dropna().unique()\n",
    "print(\"Unique positions found:\", unique_positions)\n",
    "print(\"Total unique positions:\", len(unique_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of fine-grained positions → high-level buckets\n",
    "position_bucket_map = {\n",
    "    \"GK\": \"sub\",       # treat as non-field player for running\n",
    "    \"SUB\": \"sub\",\n",
    "    \n",
    "    # Defenders\n",
    "    \"CB\": \"defender\",\n",
    "    \"RCB\": \"defender\",\n",
    "    \"LCB\": \"defender\",\n",
    "    \"RB\": \"defender\",\n",
    "    \"LB\": \"defender\",\n",
    "    \"RWB\": \"defender\",\n",
    "    \"LWB\": \"defender\",\n",
    "    \n",
    "    # Midfielders\n",
    "    \"CDM\": \"midfielder\",\n",
    "    \"RDM\": \"midfielder\",\n",
    "    \"LDM\": \"midfielder\",\n",
    "    \"CM\": \"midfielder\",\n",
    "    \"RCM\": \"midfielder\",\n",
    "    \"LCM\": \"midfielder\",\n",
    "    \"CAM\": \"midfielder\",\n",
    "    \"RM\": \"midfielder\",\n",
    "    \"LM\": \"midfielder\",\n",
    "    \n",
    "    # Attackers\n",
    "    \"LW\": \"attacker\",\n",
    "    \"RW\": \"attacker\",\n",
    "    \"ST\": \"attacker\",\n",
    "    \"CF\": \"attacker\",\n",
    "    \"RF\": \"attacker\",\n",
    "    \"LF\": \"attacker\",\n",
    "}\n",
    "\n",
    "# Map positions to buckets\n",
    "merged_df[\"position_bucket\"] = merged_df[\"position\"].map(\n",
    "    lambda pos: position_bucket_map.get(pos, \"unknown\")\n",
    ")\n",
    "\n",
    "print(merged_df[[\"assigned_cluster\", \"position\", \"position_bucket\"]].head(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_counts = (\n",
    "    merged_df\n",
    "    .groupby([\"assigned_cluster\", \"position_bucket\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"num_runs\")\n",
    "    .sort_values([\"assigned_cluster\", \"num_runs\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "\n",
    "bucket_pivot = (\n",
    "    bucket_counts\n",
    "    .pivot_table(index=\"assigned_cluster\", \n",
    "                 columns=\"position_bucket\", \n",
    "                 values=\"num_runs\", \n",
    "                 fill_value=0)\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_clusters_grid(cluster_control_points, final_runs_df, assignments, samples_per_cluster=50, rows=10, cols=7):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Convert assignments to a DataFrame for easy filtering\n",
    "    assignments_df = pd.DataFrame(assignments)\n",
    "\n",
    "    for cluster_idx in range(len(cluster_control_points)):\n",
    "        ax = axes[cluster_idx]\n",
    "\n",
    "        # Plot Bézier center curve\n",
    "        bezier_curve = evaluate_bezier_curve(cluster_control_points[cluster_idx], num_points=50)\n",
    "        ax.plot(bezier_curve[:, 0], bezier_curve[:, 1], 'k-', linewidth=2, label=\"Cluster\")\n",
    "\n",
    "        # Find runs assigned to this cluster\n",
    "        run_ids_in_cluster = assignments_df.loc[\n",
    "            assignments_df[\"assigned_cluster\"] == cluster_idx, \"run_id\"\n",
    "        ].tolist()\n",
    "\n",
    "        # Randomly sample some of them\n",
    "        if run_ids_in_cluster:\n",
    "            sampled_run_ids = random.sample(\n",
    "                run_ids_in_cluster,\n",
    "                min(samples_per_cluster, len(run_ids_in_cluster))\n",
    "            )\n",
    "\n",
    "            for run_id in sampled_run_ids:\n",
    "                run_df = final_runs_df[final_runs_df[\"run_id\"] == run_id]\n",
    "                coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "                ax.plot(coords[:, 0], coords[:, 1], alpha=0.5)\n",
    "\n",
    "        ax.set_title(f\"Cluster {cluster_idx}\\n(n={len(run_ids_in_cluster)})\", fontsize=9)\n",
    "        ax.axis(\"equal\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for i in range(len(cluster_control_points), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_all_clusters_grid(cluster_control_points, final_runs_df, assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pitch(ax, pitch_length=105, pitch_width=68):\n",
    "    \"\"\"\n",
    "    Draws a football pitch centered around (0, 0) on the given matplotlib axis.\n",
    "    \"\"\"\n",
    "    half_length = pitch_length / 2\n",
    "    half_width = pitch_width / 2\n",
    "\n",
    "    # Outer boundary & centre line\n",
    "    ax.plot([-half_length, -half_length, half_length, half_length, -half_length],\n",
    "            [-half_width, half_width, half_width, -half_width, -half_width], color=\"black\")\n",
    "    ax.plot([0, 0], [-half_width, half_width], color=\"black\")\n",
    "\n",
    "    # Left penalty area\n",
    "    ax.plot([-half_length + 16.5, -half_length + 16.5], [-13.84, 13.84], color=\"black\")\n",
    "    ax.plot([-half_length, -half_length + 16.5], [-13.84, -13.84], color=\"black\")\n",
    "    ax.plot([-half_length, -half_length + 16.5], [13.84, 13.84], color=\"black\")\n",
    "\n",
    "    # Right penalty area\n",
    "    ax.plot([half_length - 16.5, half_length - 16.5], [-13.84, 13.84], color=\"black\")\n",
    "    ax.plot([half_length, half_length - 16.5], [-13.84, -13.84], color=\"black\")\n",
    "    ax.plot([half_length, half_length - 16.5], [13.84, 13.84], color=\"black\")\n",
    "\n",
    "    # Center circle\n",
    "    circle = plt.Circle((0, 0), 9.15, color=\"black\", fill=False)\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "    ax.set_xlim(-half_length, half_length)\n",
    "    ax.set_ylim(-half_width, half_width)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_cluster_trajectories_on_pitch(\n",
    "    final_runs_df,\n",
    "    assignments_zones,\n",
    "    cluster_control_points,\n",
    "    bucket_pivot,\n",
    "    num_control_points=4,\n",
    "    max_runs_per_cluster=30,\n",
    "    plot_absolute_positions=True,\n",
    "    start_zones=None,\n",
    "    end_zones=None,\n",
    "    phases_of_play=None,\n",
    "    positions=None,\n",
    "    use_absolute_zones=False,\n",
    "    start_zones_absolute=None,\n",
    "    end_zones_absolute=None,\n",
    "    run_angle_range = None, #tuple of (min_angle, max_angle) in degrees\n",
    "    run_forward = None, #bool, whether to filter for forward runs only\n",
    "    run_length_range = None, #tuple of (min_length, max_length) in meters\n",
    "    mean_speed_range = None, #tuple of (min_speed, max_speed) in meters per second\n",
    "    max_speed_range = None, #tuple of (min_speed, max_speed)\n",
    "    tactical_overlap=None,\n",
    "    tactical_underlap=None,\n",
    "    tactical_diagonal=None\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    num_clusters = len(cluster_control_points)\n",
    "    fig, axes = plt.subplots(7, 10, figsize=(30, 20))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # --- FILTERING ---\n",
    "    filtered_assignments = assignments_zones.copy()\n",
    "\n",
    "    if start_zones is not None and not use_absolute_zones:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"start_zone\"].isin(start_zones)\n",
    "        ]\n",
    "\n",
    "    if end_zones is not None and not use_absolute_zones:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"end_zone\"].isin(end_zones)\n",
    "        ]\n",
    "\n",
    "    if start_zones_absolute is not None and use_absolute_zones:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"start_zone_absolute\"].isin(start_zones_absolute)\n",
    "        ]\n",
    "\n",
    "    if end_zones_absolute is not None and use_absolute_zones:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"end_zone_absolute\"].isin(end_zones_absolute)\n",
    "        ]\n",
    "\n",
    "    if phases_of_play is not None:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"phase_of_play\"].isin(phases_of_play)\n",
    "        ]\n",
    "\n",
    "    if positions is not None:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"position\"].isin(positions)\n",
    "        ]\n",
    "\n",
    "    if run_angle_range is not None:\n",
    "        min_angle, max_angle = run_angle_range\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            (filtered_assignments[\"run_angle_deg\"] >= min_angle) &\n",
    "            (filtered_assignments[\"run_angle_deg\"] <= max_angle)]\n",
    "    \n",
    "    if run_forward is not None: \n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"run_forward\"] == run_forward]\n",
    "    \n",
    "    if run_length_range is not None:\n",
    "        min_len, max_len = run_length_range\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            (filtered_assignments[\"run_length_m\"] >= min_len) &\n",
    "            (filtered_assignments[\"run_length_m\"] <= max_len)\n",
    "        ]\n",
    "\n",
    "    if mean_speed_range is not None:\n",
    "        min_speed, max_speed = mean_speed_range\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            (filtered_assignments[\"mean_speed\"] >= min_speed) &\n",
    "            (filtered_assignments[\"mean_speed\"] <= max_speed)\n",
    "        ]\n",
    "\n",
    "    if max_speed_range is not None:\n",
    "        min_speed, max_speed = max_speed_range\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            (filtered_assignments[\"max_speed\"] >= min_speed) &\n",
    "            (filtered_assignments[\"max_speed\"] <= max_speed)\n",
    "        ]\n",
    "\n",
    "    if tactical_overlap is not None:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"tactical_overlap\"] == tactical_overlap\n",
    "        ]\n",
    "\n",
    "    if tactical_underlap is not None:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"tactical_underlap\"] == tactical_underlap\n",
    "        ]\n",
    "\n",
    "    if tactical_diagonal is not None:\n",
    "        filtered_assignments = filtered_assignments[\n",
    "            filtered_assignments[\"tactical_diagonal\"] == tactical_diagonal\n",
    "        ]\n",
    "\n",
    "    filtered_run_ids = filtered_assignments[\"run_id\"].unique()\n",
    "\n",
    "    bucket_pivot = bucket_pivot.set_index(\"assigned_cluster\")\n",
    "\n",
    "    for cluster_idx in range(num_clusters):\n",
    "        ax = axes[cluster_idx]\n",
    "        draw_pitch(ax)\n",
    "\n",
    "        cluster_run_ids = assignments_zones.loc[\n",
    "            assignments_zones[\"assigned_cluster\"] == cluster_idx, \"run_id\"\n",
    "        ].tolist()\n",
    "\n",
    "        cluster_run_ids = [\n",
    "            rid for rid in cluster_run_ids if rid in filtered_run_ids\n",
    "        ]\n",
    "\n",
    "        if len(cluster_run_ids) > max_runs_per_cluster:\n",
    "            cluster_run_ids = random.sample(cluster_run_ids, max_runs_per_cluster)\n",
    "\n",
    "        for run_id in cluster_run_ids:\n",
    "            run_df = final_runs_df[final_runs_df[\"run_id\"] == run_id]\n",
    "\n",
    "            coords = run_df[[\"x_mirror_c\", \"y_mirror_c\"]].values\n",
    "            if coords.shape[0] < 2:\n",
    "                continue\n",
    "\n",
    "            resampled = resample_coords(coords, num_points=50)\n",
    "            control_pts = fit_bezier_curve(resampled, num_control_points)\n",
    "\n",
    "            if plot_absolute_positions:\n",
    "                start_pos = run_df[[\"x\", \"y\"]].values[0]\n",
    "                shifted_ctrl_pts = control_pts - control_pts[0] + start_pos\n",
    "                bezier_curve = evaluate_bezier_curve(\n",
    "                    shifted_ctrl_pts, num_points=50\n",
    "                )\n",
    "            else:\n",
    "                bezier_curve = evaluate_bezier_curve(\n",
    "                    control_pts, num_points=50\n",
    "                )\n",
    "\n",
    "            ax.plot(bezier_curve[:, 0], bezier_curve[:, 1], alpha=0.2, color=\"blue\")\n",
    "\n",
    "        if cluster_idx in bucket_pivot.index:\n",
    "            row = bucket_pivot.loc[cluster_idx]\n",
    "            text_lines = []\n",
    "            for bucket in [\"attacker\", \"midfielder\", \"defender\", \"sub\", \"unknown\"]:\n",
    "                if bucket in row and row[bucket] > 0:\n",
    "                    text_lines.append(f\"{bucket}: {int(row[bucket])}\")\n",
    "            text = \"\\n\".join(text_lines)\n",
    "            ax.text(\n",
    "                0.5, 1.2, text,\n",
    "                transform=ax.transAxes,\n",
    "                ha=\"center\", va=\"bottom\",\n",
    "                fontsize=8,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
    "            )\n",
    "\n",
    "        ax.set_title(f\"Cluster {cluster_idx}\", fontsize=8)\n",
    "\n",
    "    for i in range(num_clusters, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"All Bézier Run Trajectories per Cluster (On-Pitch View)\", fontsize=16, y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Define edges matching your pitch grid\n",
    "x_edges = np.linspace(-52.5, 52.5, 4)\n",
    "y_edges = np.linspace(-34, 34, 4)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Draw pitch outline\n",
    "draw_pitch(ax)\n",
    "\n",
    "zone_idx = 1\n",
    "\n",
    "# Draw zone rectangles and labels\n",
    "for y_bin in range(3):\n",
    "    for x_bin in range(3):\n",
    "        x_left = x_edges[x_bin]\n",
    "        x_right = x_edges[x_bin + 1]\n",
    "        y_bottom = y_edges[y_bin]\n",
    "        y_top = y_edges[y_bin + 1]\n",
    "\n",
    "        width = x_right - x_left\n",
    "        height = y_top - y_bottom\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_left, y_bottom),\n",
    "            width,\n",
    "            height,\n",
    "            linewidth=1,\n",
    "            edgecolor='black',\n",
    "            facecolor='lightgrey',\n",
    "            alpha=0.2\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Label in center\n",
    "        x_center = (x_left + x_right) / 2\n",
    "        y_center = (y_bottom + y_top) / 2\n",
    "\n",
    "        ax.text(\n",
    "            x_center, y_center,\n",
    "            str(zone_idx),\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            fontsize=14,\n",
    "            fontweight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "\n",
    "        zone_idx += 1\n",
    "\n",
    "ax.set_title(\"Zone Legend\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cluster_trajectories_on_pitch(\n",
    "    final_runs_df,\n",
    "    assignments_zones,\n",
    "    cluster_control_points,\n",
    "    bucket_pivot=bucket_pivot,\n",
    "    num_control_points=4,\n",
    "    max_runs_per_cluster=200,\n",
    "    plot_absolute_positions=True,\n",
    "    start_zones=None,\n",
    "    end_zones=None,  # You can specify zones like [1, 2, 3] if you want to filter\n",
    "    phases_of_play=None,\n",
    "    positions=None,\n",
    "    use_absolute_zones=True, # True or False are options\n",
    "    start_zones_absolute=None,\n",
    "    end_zones_absolute=None,\n",
    "    run_angle_range=None,  # Example: filter for runs with angles between 0 and 180 degrees\n",
    "    run_forward=True,\n",
    "    run_length_range = None,  # Example: filter for runs with length between 0 and 100 meters\n",
    "    mean_speed_range = None,  # Example: filter for runs with mean speed between 0 and 8 m/s\n",
    "    max_speed_range = None,\n",
    "    tactical_overlap=None,\n",
    "    tactical_underlap=None,\n",
    "    tactical_diagonal=True\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
